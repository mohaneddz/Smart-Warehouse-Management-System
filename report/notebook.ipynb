{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13f0cca4",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97477a15",
   "metadata": {},
   "source": [
    "## Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0eaa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum, auto\n",
    "from typing import Protocol, List, Optional, Dict, Tuple, Any\n",
    "from datetime import datetime\n",
    "from dataclasses import dataclass\n",
    "from backend.core import Node\n",
    "from backend.core import Task\n",
    "from backend.core import Warehouse\n",
    "\n",
    "# Enums\n",
    "class AgentStatus(Enum):\n",
    "    \"\"\"Possible states of an agent.\"\"\"\n",
    "    IDLE = \"IDLE\"\n",
    "    MOVING = \"MOVING\"\n",
    "    WORKING = \"WORKING\"\n",
    "    CHARGING = \"CHARGING\"\n",
    "    ERROR = \"ERROR\"\n",
    "\n",
    "class AgentType(Enum):\n",
    "    \"\"\"Types of agents in the warehouse.\"\"\"\n",
    "    PICKER = \"PICKER\"\n",
    "    TRANSPORTER = \"TRANSPORTER\"\n",
    "\n",
    "class NodeType(Enum):\n",
    "    \"\"\"Types of nodes in the warehouse.\"\"\"\n",
    "    ENTRY = \"ENTRY\"\n",
    "    EXIT = \"EXIT\"\n",
    "    NORMAL = \"NORMAL\"\n",
    "    CENTER = \"CENTER\"\n",
    "\n",
    "class TaskType(Enum):\n",
    "    \"\"\"Types of tasks in the warehouse.\"\"\"\n",
    "    PICK = \"PICK\"\n",
    "    PLACE = \"PLACE\"\n",
    "    MOVE = \"MOVE\"\n",
    "    CHARGE = \"CHARGE\"\n",
    "\n",
    "class TaskStatus(Enum):\n",
    "    \"\"\"Possible states of a task.\"\"\"\n",
    "    PENDING = \"PENDING\"\n",
    "    IN_PROGRESS = \"IN_PROGRESS\"\n",
    "    COMPLETED = \"COMPLETED\"\n",
    "    FAILED = \"FAILED\"\n",
    "\n",
    "# Protocols\n",
    "class INode(Protocol):\n",
    "    \"\"\"Protocol defining the interface for a Node.\"\"\"\n",
    "    hash: str\n",
    "    x: float\n",
    "    y: float\n",
    "    neighbours: Dict['INode', float]\n",
    "    heuristic: float\n",
    "    type: NodeType\n",
    "    locked: bool\n",
    "    is_goal: bool\n",
    "\n",
    "class IAgent(Protocol):\n",
    "    \"\"\"Interface for agent objects.\"\"\"\n",
    "    agent_id: int\n",
    "    node: 'Node'\n",
    "    weight: float\n",
    "    status: AgentStatus\n",
    "    goal_state: str\n",
    "    mixer: Optional['IMixer']\n",
    "    path: List['Node']\n",
    "    battery: float\n",
    "    agent_type: AgentType\n",
    "    hash_id: str\n",
    "\n",
    "class IMixer(Protocol):\n",
    "    \"\"\"Interface for mixer objects.\"\"\"\n",
    "    warehouse: 'Warehouse'\n",
    "    tasks: List['Task']\n",
    "    priority_tasks: List['Task']\n",
    "    agents: Dict[str, IAgent]\n",
    "    logs: List[str]\n",
    "    log_file: str\n",
    "\n",
    "    def log_event(self, event_type: str, message: str, agent: Optional[IAgent] = None, task: Optional['Task'] = None) -> None:\n",
    "        \"\"\"Logs an event in the system.\"\"\"\n",
    "        pass\n",
    "\n",
    "class ITask(Protocol):\n",
    "    \"\"\"Protocol defining the interface for a Task.\"\"\"\n",
    "    hash_id: str\n",
    "    initial_state: str\n",
    "    goal_state: str\n",
    "    job: TaskType\n",
    "    priority: int\n",
    "\n",
    "# Schema Classes\n",
    "@dataclass\n",
    "class ItemInformation:\n",
    "    \"\"\"Schema for storing item information in the warehouse system.\"\"\"\n",
    "    item_id: str  # PK\n",
    "    name: str\n",
    "    category: str\n",
    "    box_weight: float\n",
    "    box_height: float\n",
    "    box_price: float\n",
    "    expiry: Optional[datetime]\n",
    "    counter: int = 0\n",
    "\n",
    "@dataclass\n",
    "class ItemShelf:\n",
    "    \"\"\"Schema for mapping items to shelves in the warehouse.\"\"\"\n",
    "    item_id: str  # FK\n",
    "    shelf_id: str  # FK\n",
    "    order_in_shelf: int\n",
    "    addition_date: datetime\n",
    "    accessible_nodes: List[str]\n",
    "    finale: bool = False\n",
    "\n",
    "@dataclass\n",
    "class Rack:\n",
    "    \"\"\"Schema for storage racks in the warehouse.\"\"\"\n",
    "    rack_id: str  # PK\n",
    "    is_frozen: bool\n",
    "    current_capacity: float\n",
    "    start_coords: Tuple[float, float]  # [x,y]\n",
    "    center_coords: Tuple[float, float]  # [x,y]\n",
    "    end_coords: Tuple[float, float]    # [x,y]\n",
    "\n",
    "@dataclass\n",
    "class Shelf:\n",
    "    \"\"\"Schema for shelves within racks.\"\"\"\n",
    "    shelf_id: str  # PK\n",
    "    rack_id: str   # FK -> Rack\n",
    "    z_level: float\n",
    "    current_weight: float\n",
    "    is_locked: bool = False\n",
    "\n",
    "@dataclass\n",
    "class FactsTable:\n",
    "    \"\"\"Schema for warehouse configuration and constraints.\"\"\"\n",
    "    name: str\n",
    "    location: str\n",
    "    warehouse_width: float\n",
    "    warehouse_length: float\n",
    "    warehouse_height: float\n",
    "    n_racks: int\n",
    "    n_shelfs_per_rack: int\n",
    "    shelfs_max_height: List[float]  # [z1,z2..]\n",
    "    shelf_max_width: float\n",
    "    item_length: float\n",
    "\n",
    "@dataclass\n",
    "class Transaction:\n",
    "    \"\"\"Schema for warehouse transactions.\"\"\"\n",
    "    transaction_id: str  # PK\n",
    "    transaction_type: str\n",
    "    item_id: str  # FK -> ItemInformation\n",
    "    quantity: int\n",
    "    date: datetime "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0ab2a0",
   "metadata": {},
   "source": [
    "## Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4691a722",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "import uuid\n",
    "from core.types import TaskType, ITask\n",
    "\n",
    "class Task(ITask):\n",
    "    \"\"\"Represents a task to be performed by an agent within the warehouse environment.\n",
    "    \n",
    "    Attributes:\n",
    "        hash_id (str): Unique identifier for the task\n",
    "        initial_state (str): Starting state/location of the task\n",
    "        goal_state (str): Target state/location for the task\n",
    "        job (TaskType): Type of job to be performed\n",
    "        priority (int): Priority level of the task (0 = normal, 1 = high)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, goal_state: str, job: TaskType, priority: int = 0, initial_state: str = \"\", hash_id: Optional[str] = None):\n",
    "        \"\"\"Initializes a Task instance.\n",
    "\n",
    "        Args:\n",
    "            goal_state (str): Description or identifier of the target state/location for the task.\n",
    "            job (TaskType): The type of job to be performed\n",
    "            priority (int, optional): The priority level of the task (0 = normal, 1 = high)\n",
    "            initial_state (str, optional): Description or identifier of the starting state/location\n",
    "            hash_id (Optional[str], optional): A unique identifier (Primary Key) for the task\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If goal_state or job is empty, or if priority is negative\n",
    "        \"\"\"\n",
    "        if not goal_state:\n",
    "            raise ValueError(\"Goal state cannot be empty\")\n",
    "        if not job:\n",
    "            raise ValueError(\"Job type cannot be empty\")\n",
    "        if priority < 0:\n",
    "            raise ValueError(\"Priority cannot be negative\")\n",
    "\n",
    "        self.hash_id: str = hash_id if hash_id is not None else str(uuid.uuid4())\n",
    "        self.initial_state: str = initial_state\n",
    "        self.goal_state: str = goal_state\n",
    "        self.job: TaskType = job\n",
    "        self.priority: int = priority\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        \"\"\"Return a string representation of the task.\n",
    "        \n",
    "        Returns:\n",
    "            str: A human-readable string representation of the task\n",
    "        \"\"\"\n",
    "        return f\"Task(Job='{self.job.name}', Goal='{self.goal_state}', Priority={self.priority}, ID='{self.hash_id}')\"\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        \"\"\"Return a detailed string representation for debugging.\n",
    "        \n",
    "        Returns:\n",
    "            str: A detailed string representation of the task\n",
    "        \"\"\"\n",
    "        return (f\"Task(hash_id='{self.hash_id}', initial_state='{self.initial_state}', \"\n",
    "                f\"goal_state='{self.goal_state}', job='{self.job.name}', priority={self.priority})\")\n",
    "\n",
    "    def __eq__(self, other: object) -> bool:\n",
    "        \"\"\"Check if two tasks are equal based on their unique hash_id.\n",
    "        \n",
    "        Args:\n",
    "            other (object): The object to compare with\n",
    "            \n",
    "        Returns:\n",
    "            bool: True if the tasks are equal, False otherwise\n",
    "        \"\"\"\n",
    "        if not isinstance(other, Task):\n",
    "            return NotImplemented\n",
    "        return self.hash_id == other.hash_id\n",
    "\n",
    "    def __hash__(self) -> int:\n",
    "        \"\"\"Return a hash based on the task's unique hash_id.\n",
    "        \n",
    "        Returns:\n",
    "            int: A hash value computed from the task's hash_id\n",
    "        \"\"\"\n",
    "        return hash(self.hash_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3ff766",
   "metadata": {},
   "source": [
    "## Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bbf020",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Optional, List\n",
    "from enum import Enum, auto\n",
    "from core.types import NodeType, INode, IAgent\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "class NodeType(Enum):\n",
    "    \"\"\"Enumeration of possible node types.\"\"\"\n",
    "    NORMAL = auto()\n",
    "    CENTER = auto()\n",
    "\n",
    "@dataclass\n",
    "class Node:\n",
    "    \"\"\"Represents a node in the warehouse grid.\n",
    "    \n",
    "    Attributes:\n",
    "        x (int): X coordinate\n",
    "        y (int): Y coordinate\n",
    "        node_type (NodeType): Type of the node\n",
    "        name (str): Name of the node (e.g., \"A1\", \"B2\")\n",
    "        neighbours (Dict[Node, float]): Dictionary of neighboring nodes and their distances\n",
    "        locked_by (Optional[str]): ID of the agent that has locked this node\n",
    "    \"\"\"\n",
    "    x: int\n",
    "    y: int\n",
    "    node_type: NodeType\n",
    "    name: str\n",
    "    neighbours: Dict['Node', float] = field(default_factory=dict)\n",
    "    locked_by: Optional[str] = None\n",
    "    locked: bool = False\n",
    "    is_goal: bool = False\n",
    "\n",
    "    def add_neighbor(self, node: 'Node', distance: float = 1.0) -> None:\n",
    "        \"\"\"Adds a neighboring node with the given distance.\"\"\"\n",
    "        self.neighbours[node] = distance\n",
    "        node.neighbours[self] = distance\n",
    "\n",
    "    def is_locked(self) -> bool:\n",
    "        \"\"\"Returns whether the node is currently locked by an agent.\"\"\"\n",
    "        return self.locked\n",
    "\n",
    "    def lock(self, agent_id: str) -> bool:\n",
    "        \"\"\"Attempts to lock the node for an agent.\n",
    "        \n",
    "        Args:\n",
    "            agent_id (str): ID of the agent attempting to lock the node\n",
    "            \n",
    "        Returns:\n",
    "            bool: True if the node was successfully locked, False otherwise\n",
    "        \"\"\"\n",
    "        if not self.is_locked():\n",
    "            self.locked = True\n",
    "            self.locked_by = agent_id\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def unlock(self, agent_id: str) -> bool:\n",
    "        \"\"\"Attempts to unlock the node for an agent.\n",
    "        \n",
    "        Args:\n",
    "            agent_id (str): ID of the agent attempting to unlock the node\n",
    "            \n",
    "        Returns:\n",
    "            bool: True if the node was successfully unlocked, False otherwise\n",
    "        \"\"\"\n",
    "        if self.locked and self.locked_by == agent_id:\n",
    "            self.locked = False\n",
    "            self.locked_by = None\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def __hash__(self) -> int:\n",
    "        \"\"\"Returns a hash value for the node.\"\"\"\n",
    "        return hash((self.x, self.y))\n",
    "\n",
    "    def __eq__(self, other: object) -> bool:\n",
    "        \"\"\"Checks if two nodes are equal.\"\"\"\n",
    "        if not isinstance(other, Node):\n",
    "            return False\n",
    "        return self.x == other.x and self.y == other.y\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        \"\"\"Returns a string representation of the node.\"\"\"\n",
    "        return f\"{self.name} ({self.x}, {self.y})\"\n",
    "\n",
    "    def get_locking_agent(self) -> Optional[str]:\n",
    "        \"\"\"Gets the agent that currently has the node locked.\n",
    "\n",
    "        Returns:\n",
    "            Optional[str]: The agent that locked the node, or None if the node is not locked\n",
    "        \"\"\"\n",
    "        return self.locked_by\n",
    "\n",
    "    def set_type(self, node_type: NodeType) -> None:\n",
    "        \"\"\"Sets the type of the node.\n",
    "\n",
    "        Args:\n",
    "            node_type (NodeType): The new type for the node\n",
    "        \"\"\"\n",
    "        self.node_type = node_type\n",
    "\n",
    "    def set_goal(self, is_goal: bool = True) -> None:\n",
    "        \"\"\"Sets whether this node is a goal node.\n",
    "\n",
    "        Args:\n",
    "            is_goal (bool, optional): Whether this is a goal node. Defaults to True.\n",
    "        \"\"\"\n",
    "        self.is_goal = is_goal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde3631b",
   "metadata": {},
   "source": [
    "## Warehouse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff89b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Optional, List, TYPE_CHECKING\n",
    "from math import sqrt\n",
    "from core.node import Node, NodeType\n",
    "from core.task import Task\n",
    "from schema.warehouse import FactsTable\n",
    "from schema.storage import Rack, Shelf\n",
    "from dataclasses import dataclass, field\n",
    "import uuid\n",
    "import json\n",
    "import os\n",
    "from core.types import AgentType\n",
    "\n",
    "if TYPE_CHECKING:\n",
    "    from backend.core.agent import Agent\n",
    "\n",
    "@dataclass\n",
    "class Warehouse:\n",
    "    \"\"\"Represents the warehouse environment.\n",
    "    \n",
    "    Attributes:\n",
    "        facts (FactsTable): Warehouse configuration and facts\n",
    "        nodes (Dict[str, Node]): All nodes in the warehouse, keyed by node name\n",
    "        racks (Dict[str, Rack]): All racks in the warehouse, keyed by rack ID\n",
    "        shelves (Dict[str, Shelf]): All shelves in the warehouse, keyed by shelf ID\n",
    "        agents (Dict[str, Agent]): All agents in the warehouse\n",
    "        tasks (List[Task]): All tasks in the warehouse\n",
    "        goal (Optional[Node]): Current goal node for pathfinding\n",
    "    \"\"\"\n",
    "    facts: FactsTable\n",
    "    nodes: Dict[str, Node] = field(default_factory=dict)\n",
    "    racks: Dict[str, Rack] = field(default_factory=dict)\n",
    "    shelves: Dict[str, Shelf] = field(default_factory=dict)\n",
    "    agents: Dict[str, 'Agent'] = field(default_factory=dict)\n",
    "    tasks: List[Task] = field(default_factory=list)\n",
    "    goal: Optional[Node] = None\n",
    "    \n",
    "    @classmethod\n",
    "    def create_default(cls) -> 'Warehouse':\n",
    "        \"\"\"Creates a default warehouse configuration for testing/example purposes.\"\"\"\n",
    "        # Create facts table\n",
    "        facts = FactsTable(\n",
    "            name=\"Example Warehouse\",\n",
    "            location=\"Test Location\",\n",
    "            warehouse_width=20.0,\n",
    "            warehouse_length=30.0,\n",
    "            warehouse_height=5.0,\n",
    "            n_racks=4,\n",
    "            n_shelfs_per_rack=3,\n",
    "            shelfs_max_height=[1.0, 2.0, 3.0],\n",
    "            shelf_max_width=2.0,\n",
    "            item_length=0.5\n",
    "        )\n",
    "        \n",
    "        # Create a 5x5 grid of nodes\n",
    "        nodes: Dict[str, Node] = {}\n",
    "        for i in range(5):\n",
    "            for j in range(5):\n",
    "                node_hash = f\"node_{i}_{j}\"\n",
    "                nodes[node_hash] = Node(float(i), float(j), node_hash, {}, 0.0)\n",
    "        \n",
    "        # Connect nodes (up, down, left, right)\n",
    "        for i in range(5):\n",
    "            for j in range(5):\n",
    "                current = nodes[f\"node_{i}_{j}\"]\n",
    "                neighbors = {}\n",
    "                \n",
    "                # Check all adjacent positions\n",
    "                for di, dj in [(0, 1), (0, -1), (1, 0), (-1, 0)]:\n",
    "                    ni, nj = i + di, j + dj\n",
    "                    if 0 <= ni < 5 and 0 <= nj < 5:\n",
    "                        neighbor = nodes[f\"node_{ni}_{nj}\"]\n",
    "                        neighbors[neighbor] = 1.0\n",
    "                \n",
    "                current.neighbours = neighbors\n",
    "        \n",
    "        # Create racks\n",
    "        racks: Dict[str, Rack] = {}\n",
    "        rack_positions = [(1, 1), (1, 3), (3, 1), (3, 3)]\n",
    "        for i, (x, y) in enumerate(rack_positions):\n",
    "            rack_id = f\"rack_{i+1}\"\n",
    "            racks[rack_id] = Rack(\n",
    "                rack_id=rack_id,\n",
    "                is_frozen=False,\n",
    "                current_capacity=0.0,\n",
    "                start_coords=(float(x-0.5), float(y-0.5)),\n",
    "                center_coords=(float(x), float(y)),\n",
    "                end_coords=(float(x+0.5), float(y+0.5))\n",
    "            )\n",
    "            # Mark the node as a center\n",
    "            nodes[f\"node_{x}_{y}\"].set_type(NodeType.CENTER)\n",
    "        \n",
    "        # Create shelves\n",
    "        shelves: Dict[str, Shelf] = {}\n",
    "        for rack_id, rack in racks.items():\n",
    "            for level in range(3):\n",
    "                shelf_id = f\"{rack_id}_shelf_{level+1}\"\n",
    "                shelves[shelf_id] = Shelf(\n",
    "                    shelf_id=shelf_id,\n",
    "                    rack_id=rack_id,\n",
    "                    z_level=float(level + 1),\n",
    "                    current_weight=0.0,\n",
    "                    is_locked=False\n",
    "                )\n",
    "        \n",
    "        return cls(facts=facts, nodes=nodes, racks=racks, shelves=shelves)\n",
    "    \n",
    "    @classmethod\n",
    "    def load_from_json(cls, json_path: str) -> 'Warehouse':\n",
    "        \"\"\"Loads warehouse configuration from a JSON file.\n",
    "        \n",
    "        Args:\n",
    "            json_path (str): Path to the JSON configuration file\n",
    "            \n",
    "        Returns:\n",
    "            Warehouse: A new Warehouse instance with the loaded configuration\n",
    "            \n",
    "        Raises:\n",
    "            ValueError: If the JSON file is invalid or missing required fields\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with open(json_path, 'r') as f:\n",
    "                config = json.load(f)\n",
    "                \n",
    "            # Create default facts table\n",
    "            facts = FactsTable(\n",
    "                name=\"Warehouse\",\n",
    "                location=\"Default\",\n",
    "                warehouse_width=20.0,  # meters\n",
    "                warehouse_length=30.0,  # meters\n",
    "                warehouse_height=5.0,   # meters\n",
    "                n_racks=5,             # number of racks\n",
    "                n_shelfs_per_rack=3,   # shelves per rack\n",
    "                shelfs_max_height=[1.0, 2.0, 3.0],  # height of each shelf level\n",
    "                shelf_max_width=2.0,   # meters\n",
    "                item_length=0.5        # meters\n",
    "            )\n",
    "                \n",
    "            # Create warehouse instance with facts\n",
    "            warehouse = cls(facts=facts)\n",
    "            \n",
    "            # Create nodes\n",
    "            nodes = {}\n",
    "            for node_name, node_data in config['nodes'].items():\n",
    "                # Convert node type string to enum\n",
    "                try:\n",
    "                    node_type = NodeType[node_data['type']]\n",
    "                except KeyError:\n",
    "                    raise ValueError(f\"Invalid node type: {node_data['type']}\")\n",
    "                    \n",
    "                node = Node(\n",
    "                    x=node_data['x'],\n",
    "                    y=node_data['y'],\n",
    "                    node_type=node_type,\n",
    "                    name=node_name\n",
    "                )\n",
    "                nodes[node_name] = node\n",
    "                \n",
    "            # Create connections\n",
    "            for node1_name, node2_name in config['connections']:\n",
    "                node1 = nodes[node1_name]\n",
    "                node2 = nodes[node2_name]\n",
    "                node1.add_neighbor(node2)\n",
    "                node2.add_neighbor(node1)\n",
    "                \n",
    "            warehouse.nodes = list(nodes.values())\n",
    "            \n",
    "            # Create racks and shelves\n",
    "            for rack_id, rack_data in config['racks'].items():\n",
    "                center_node = nodes[rack_data['center']]\n",
    "                rack = Rack(\n",
    "                    rack_id=rack_id,\n",
    "                    is_frozen=False,\n",
    "                    current_capacity=0.0,\n",
    "                    start_coords=(center_node.x - 0.5, center_node.y - 0.5),\n",
    "                    center_coords=(center_node.x, center_node.y),\n",
    "                    end_coords=(center_node.x + 0.5, center_node.y + 0.5)\n",
    "                )\n",
    "                warehouse.racks.append(rack)\n",
    "                \n",
    "                # Create shelves for the rack\n",
    "                for shelf_id in rack_data['shelves']:\n",
    "                    shelf = Shelf(\n",
    "                        shelf_id=shelf_id,\n",
    "                        rack_id=rack.rack_id,\n",
    "                        z_level=len(rack.shelves) + 1,\n",
    "                        current_weight=0.0,\n",
    "                        is_locked=False\n",
    "                    )\n",
    "                    warehouse.shelves.append(shelf)\n",
    "                    \n",
    "            return warehouse\n",
    "            \n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Failed to load warehouse from {json_path}: {str(e)}\")\n",
    "    \n",
    "    def get_node(self, x: int, y: int) -> Optional[Node]:\n",
    "        \"\"\"Returns the node at the given coordinates.\"\"\"\n",
    "        for node in self.nodes.values():\n",
    "            if node.x == x and node.y == y:\n",
    "                return node\n",
    "        return None\n",
    "\n",
    "    def get_node_by_name(self, name: str) -> Optional[Node]:\n",
    "        \"\"\"Returns the node with the given name.\"\"\"\n",
    "        return self.nodes.get(name)\n",
    "\n",
    "    def get_rack_at_node(self, node: Node) -> Optional[Rack]:\n",
    "        \"\"\"Returns the rack at the given node.\"\"\"\n",
    "        for rack in self.racks.values():\n",
    "            if rack.center_node == node:\n",
    "                return rack\n",
    "        return None\n",
    "\n",
    "    def get_shelves_for_rack(self, rack: Rack) -> List[Shelf]:\n",
    "        \"\"\"Returns all shelves in the given rack.\"\"\"\n",
    "        return list(rack.shelves.values())\n",
    "\n",
    "    def get_distance(self, n1: Node, n2: Node) -> float:\n",
    "        \"\"\"Calculates Euclidean distance between two nodes.\n",
    "\n",
    "        Args:\n",
    "            n1 (Node): First node.\n",
    "            n2 (Node): Second node.\n",
    "\n",
    "        Returns:\n",
    "            float: Euclidean distance between n1 and n2.\n",
    "        \"\"\"\n",
    "        return sqrt((n1.x - n2.x) ** 2 + (n1.y - n2.y) ** 2)\n",
    "\n",
    "    def get_actions(self, node: Node) -> Dict[str, float]:\n",
    "        \"\"\"Returns a dictionary of possible actions (neighboring nodes) from a given node.\n",
    "\n",
    "        Args:\n",
    "            node (Node): The node to get actions from.\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, float]: Dictionary of neighboring nodes and their distances.\n",
    "        \"\"\"\n",
    "        return {k: v for k, v in node.neighbours.items() if k != node.parent}\n",
    "\n",
    "    def assign_heuristics(self):\n",
    "        \"\"\"Assigns heuristic values to nodes based on the goal location.\"\"\"\n",
    "        if not self.goal:\n",
    "            return\n",
    "        for node in self.nodes.values():\n",
    "            node.set_heuristic(self.get_distance(node, self.goal))\n",
    "\n",
    "    def add_task(self, task: Task):\n",
    "        \"\"\"Adds a task to the warehouse task list.\n",
    "\n",
    "        Args:\n",
    "            task (Task): The task to add.\n",
    "        \"\"\"\n",
    "        self.tasks.append(task)\n",
    "\n",
    "    def assign_task(self, agent: 'Agent'):\n",
    "        \"\"\"Assigns the highest priority task to an agent.\n",
    "\n",
    "        Args:\n",
    "            agent (Agent): The agent to assign the task to.\n",
    "        \"\"\"\n",
    "        if self.tasks:\n",
    "            # Sort tasks by priority (lower priority value means higher priority)\n",
    "            self.tasks.sort(key=lambda x: x.priority)\n",
    "            task = self.tasks.pop(0)  # Get the highest priority task\n",
    "            agent.set_goal(task.goal_state)\n",
    "            print(f\"Assigned Task {task.job} to Agent {agent}.\")\n",
    "        else:\n",
    "            print(f\"No tasks available for Agent {agent}.\")\n",
    "\n",
    "    def calculate_heuristics(self, goal_node: Node, agent_type: AgentType) -> Dict[str, float]:\n",
    "        \"\"\"Calculates heuristic values for all nodes based on the goal and agent type.\"\"\"\n",
    "        heuristics = {}\n",
    "        \n",
    "        for node_name, node in self.nodes.items():\n",
    "            # Base heuristic is Manhattan distance\n",
    "            distance = abs(node.x - goal_node.x) + abs(node.y - goal_node.y)\n",
    "            \n",
    "            # Adjust heuristic based on agent type\n",
    "            if agent_type == AgentType.PICKER:\n",
    "                # Pickers prefer paths with fewer obstacles\n",
    "                if node.type == NodeType.CENTER:\n",
    "                    distance += 2  # Penalize rack centers\n",
    "                elif node.type == NodeType.ENTRY or node.type == NodeType.EXIT:\n",
    "                    distance -= 1  # Favor entry/exit points\n",
    "            elif agent_type == AgentType.TRANSPORTER:\n",
    "                # Transporters prefer straight paths\n",
    "                if node.type == NodeType.CENTER:\n",
    "                    distance += 3  # Strongly penalize rack centers\n",
    "                elif node.type == NodeType.ENTRY or node.type == NodeType.EXIT:\n",
    "                    distance -= 2  # Strongly favor entry/exit points\n",
    "            \n",
    "            heuristics[node_name] = distance\n",
    "            \n",
    "        return heuristics\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"String representation of the Warehouse map.\"\"\"\n",
    "        return f\"Warehouse(Agents: {len(self.agents)}, Tasks: {len(self.tasks)})\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18678dcf",
   "metadata": {},
   "source": [
    "## Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e50bef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from dataclasses import dataclass, field\n",
    "import uuid\n",
    "from core.types import AgentStatus, AgentType, IMixer, IAgent\n",
    "from core.node import Node\n",
    "from core.task import Task\n",
    "\n",
    "@dataclass\n",
    "class Agent(IAgent):\n",
    "    \"\"\"Represents an agent in the warehouse system.\n",
    "    \n",
    "    Attributes:\n",
    "        agent_id (int): Unique identifier for the agent\n",
    "        node (Node): Current node where the agent is located\n",
    "        weight (float): Weight of the agent (used for priority)\n",
    "        status (AgentStatus): Current status of the agent\n",
    "        goal_state (str): Target state/location for the agent\n",
    "        mixer (Optional[IMixer]): Reference to the global mixer instance\n",
    "        path (List[Node]): Current planned path\n",
    "        battery (float): Current battery level (0-100)\n",
    "        agent_type (AgentType): Type of agent\n",
    "    \"\"\"\n",
    "    agent_id: int\n",
    "    node: Node\n",
    "    weight: float\n",
    "    status: AgentStatus = AgentStatus.IDLE\n",
    "    goal_state: str = \"\"\n",
    "    mixer: Optional[IMixer] = None\n",
    "    path: List[Node] = field(default_factory=list)\n",
    "    battery: float = 100.0\n",
    "    agent_type: AgentType = AgentType.PICKER\n",
    "    hash_id: str = field(default_factory=lambda: str(uuid.uuid4()))\n",
    "\n",
    "    def __post_init__(self):\n",
    "        \"\"\"Initializes an Agent with its node and registers with the mixer.\"\"\"\n",
    "        if not self.node:\n",
    "            raise ValueError(\"Agent must be initialized with a valid node\")\n",
    "            \n",
    "        # Add initial node to path\n",
    "        self.path.append(self.node)\n",
    "        if not self.node.lock(self):\n",
    "            raise RuntimeError(f\"Failed to lock initial node {self.node}\")\n",
    "            \n",
    "        # Register with the global Mixer if available\n",
    "        if self.mixer:\n",
    "            self.mixer.log_event('agent_creation', f\"Agent {self.agent_id} created at {self.node}\", self)\n",
    "\n",
    "    def move(self, new_node: Node) -> bool:\n",
    "        \"\"\"Moves the agent to a new node and logs the action.\"\"\"\n",
    "        if not new_node:\n",
    "            if self.mixer:\n",
    "                self.mixer.log_event('movement_failed', \"Cannot move to None node\", self)\n",
    "            return False\n",
    "            \n",
    "        # Try to lock the new node\n",
    "        if not new_node.lock(self):\n",
    "            if self.mixer:\n",
    "                self.mixer.log_event('movement_failed', f\"Failed to move to {new_node} - node locked\", self)\n",
    "            return False\n",
    "            \n",
    "        # Unlock the current node\n",
    "        self.node.unlock(self)\n",
    "        \n",
    "        # Update node and path\n",
    "        self.node = new_node\n",
    "        self.path.append(new_node)\n",
    "        \n",
    "        # Log the movement if mixer is available\n",
    "        if self.mixer:\n",
    "            self.mixer.log_event('movement', f\"Moved to {new_node}\", self)\n",
    "        return True\n",
    "\n",
    "    def backtrack(self, steps: int = 1) -> bool:\n",
    "        \"\"\"Moves the agent back along its path history.\n",
    "        \n",
    "        Args:\n",
    "            steps (int): Number of steps to backtrack\n",
    "            \n",
    "        Returns:\n",
    "            bool: True if backtrack was successful, False otherwise\n",
    "        \"\"\"\n",
    "        if steps <= 0:\n",
    "            if self.mixer:\n",
    "                self.mixer.log_event('backtrack_failed', f\"Invalid number of steps: {steps}\", self)\n",
    "            return False\n",
    "            \n",
    "        if len(self.path) <= steps:\n",
    "            if self.mixer:\n",
    "                self.mixer.log_event('backtrack_failed', f\"Not enough path history to backtrack {steps} steps\", self)\n",
    "            return False\n",
    "            \n",
    "        # Get the target node to backtrack to\n",
    "        target_node = self.path[-steps-1]\n",
    "        \n",
    "        # Try to lock the target node\n",
    "        if not target_node.lock(self):\n",
    "            if self.mixer:\n",
    "                self.mixer.log_event('backtrack_failed', f\"Failed to backtrack to {target_node} - node locked\", self)\n",
    "            return False\n",
    "            \n",
    "        # Unlock the current node\n",
    "        self.node.unlock(self)\n",
    "        \n",
    "        # Update node and path history\n",
    "        self.node = target_node\n",
    "        self.path = self.path[:-steps]\n",
    "        \n",
    "        # Log the backtrack if mixer is available\n",
    "        if self.mixer:\n",
    "            self.mixer.log_event('backtrack', f\"Backtracked {steps} steps to {target_node}\", self)\n",
    "        return True\n",
    "\n",
    "    def set_goal(self, goal: str) -> None:\n",
    "        \"\"\"Sets a new goal state for the agent.\"\"\"\n",
    "        if not goal:\n",
    "            raise ValueError(\"Goal cannot be empty\")\n",
    "            \n",
    "        self.goal_state = goal\n",
    "        if self.mixer:\n",
    "            self.mixer.log_event('goal_change', f\"Goal set to {goal}\", self)\n",
    "\n",
    "    def complete_task(self, task: Task) -> None:\n",
    "        \"\"\"Completes the given task and logs the completion.\n",
    "        \n",
    "        Args:\n",
    "            task (Task): The task to complete\n",
    "        \"\"\"\n",
    "        if not task:\n",
    "            raise ValueError(\"Task cannot be None\")\n",
    "            \n",
    "        if self.mixer:\n",
    "            self.mixer.log_event('task_completion', f\"Completed task: {task.job} to goal {task.goal_state}\", self, task)\n",
    "\n",
    "    def get_last_node(self) -> Optional[Node]:\n",
    "        \"\"\"Returns the last node in the path history.\n",
    "        \n",
    "        Returns:\n",
    "            Optional[Node]: The last node in the path history, or None if history is empty\n",
    "        \"\"\"\n",
    "        return self.path[-1] if self.path else None\n",
    "\n",
    "    def clear_path_history(self) -> None:\n",
    "        \"\"\"Clears the path history, keeping only the current node.\"\"\"\n",
    "        if self.path:\n",
    "            current_node = self.path[-1]\n",
    "            self.path = [current_node]\n",
    "            \n",
    "    def update_battery(self, level: float) -> None:\n",
    "        \"\"\"Updates the agent's battery level.\n",
    "        \n",
    "        Args:\n",
    "            level (float): New battery level (0-100)\n",
    "            \n",
    "        Raises:\n",
    "            ValueError: If battery level is not between 0 and 100\n",
    "        \"\"\"\n",
    "        if not 0 <= level <= 100:\n",
    "            raise ValueError(\"Battery level must be between 0 and 100\")\n",
    "        self.battery = level\n",
    "        \n",
    "        if self.mixer and level < 20:\n",
    "            self.mixer.log_event('battery_low', f\"Battery low ({level}%)\", self)\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        \"\"\"Returns a string representation of the agent.\"\"\"\n",
    "        return f\"Agent({self.agent_id}, {self.status.name}, {self.node})\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569044df",
   "metadata": {},
   "source": [
    "## Mixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f98037",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Optional, Any\n",
    "from queue import Queue\n",
    "from core.task import Task\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import uuid\n",
    "from core.agent import Agent\n",
    "from core.types import IMixer, IAgent, ITask\n",
    "\n",
    "class Mixer(IMixer):\n",
    "    \"\"\"Handles task assignment, prioritization, and monitoring for agents in the warehouse system.\n",
    "    Also plays the role of Monitor.\n",
    "    \n",
    "    Attributes:\n",
    "        warehouse (Dict[str, Any]): Reference to the warehouse configuration\n",
    "        tasks (Queue): Regular tasks queue\n",
    "        priority_tasks (Queue): High-priority tasks queue\n",
    "        agents (List[Agent]): List of agents in the system\n",
    "    \"\"\"\n",
    "    \n",
    "    _instance = None\n",
    "    LOG_BATCH_SIZE = 100  # Number of logs to accumulate before saving\n",
    "    \n",
    "    def __new__(cls, *args, **kwargs):\n",
    "        if cls._instance is None:\n",
    "            cls._instance = super(Mixer, cls).__new__(cls)\n",
    "            cls._instance._initialized = False\n",
    "        return cls._instance\n",
    "    \n",
    "    def __init__(self, warehouse: Any = None, agents: List[IAgent] = None):\n",
    "        if self._initialized:\n",
    "            return\n",
    "            \n",
    "        self.warehouse = warehouse  # FK\n",
    "        self.tasks = Queue()  # Regular tasks queue\n",
    "        self.priority_tasks = Queue()  # High-priority tasks queue\n",
    "        self.agents = agents or []  # FK\n",
    "        self.logs = []  # List to store all system logs\n",
    "        self._log_file_path = os.path.join(os.path.dirname(__file__), '..', 'data', 'logs')\n",
    "        self._ensure_log_directory()\n",
    "        self._initialized = True\n",
    "\n",
    "    def _ensure_log_directory(self) -> None:\n",
    "        \"\"\"Ensures the log directory exists.\"\"\"\n",
    "        os.makedirs(self._log_file_path, exist_ok=True)\n",
    "\n",
    "    def _get_log_file_path(self) -> str:\n",
    "        \"\"\"Returns the path to the current log file.\"\"\"\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d\")\n",
    "        return os.path.join(self._log_file_path, f\"warehouse_logs_{timestamp}.json\")\n",
    "\n",
    "    def _save_logs(self) -> None:\n",
    "        \"\"\"Saves the current logs to a file.\"\"\"\n",
    "        if not self.logs:\n",
    "            return\n",
    "\n",
    "        log_file = self._get_log_file_path()\n",
    "        try:\n",
    "            # Read existing logs if file exists\n",
    "            existing_logs = []\n",
    "            if os.path.exists(log_file):\n",
    "                with open(log_file, 'r') as f:\n",
    "                    existing_logs = json.load(f)\n",
    "\n",
    "            # Append new logs\n",
    "            existing_logs.extend(self.logs)\n",
    "            \n",
    "            # Save all logs\n",
    "            with open(log_file, 'w') as f:\n",
    "                json.dump(existing_logs, f, indent=2)\n",
    "            \n",
    "            # Clear the in-memory logs\n",
    "            self.logs = []\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error saving logs: {e}\")\n",
    "\n",
    "    def log_event(self, event_type: str, message: str, agent: Optional[IAgent] = None, task: Optional[ITask] = None) -> None:\n",
    "        \"\"\"Logs an event in the system and saves logs if batch size is reached.\n",
    "        \n",
    "        Args:\n",
    "            event_type (str): Type of event (e.g., 'movement', 'task', 'deadlock')\n",
    "            message (str): Description of the event\n",
    "            agent (Agent, optional): Agent involved in the event\n",
    "            task (Task, optional): Task involved in the event\n",
    "        \"\"\"\n",
    "        log_entry = {\n",
    "            'id': str(uuid.uuid4()),\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'type': event_type,\n",
    "            'message': message,\n",
    "            'agent_id': agent.hash_id if agent else None,\n",
    "            'task_id': task.hash_id if task else None\n",
    "        }\n",
    "        self.logs.append(log_entry)\n",
    "        print(f\"[{log_entry['timestamp']}] {event_type}: {message}\")\n",
    "\n",
    "        # Save logs if batch size is reached\n",
    "        if len(self.logs) >= self.LOG_BATCH_SIZE:\n",
    "            self._save_logs()\n",
    "\n",
    "    def get_logs(self, event_type: Optional[str] = None, agent_id: Optional[str] = None, task_id: Optional[str] = None) -> List[Dict]:\n",
    "        \"\"\"Retrieves logs based on filters.\n",
    "        \n",
    "        Args:\n",
    "            event_type (str, optional): Filter by event type\n",
    "            agent_id (str, optional): Filter by agent ID\n",
    "            task_id (str, optional): Filter by task ID\n",
    "            \n",
    "        Returns:\n",
    "            List[dict]: Filtered log entries\n",
    "        \"\"\"\n",
    "        filtered_logs = self.logs\n",
    "        if event_type:\n",
    "            filtered_logs = [log for log in filtered_logs if log['type'] == event_type]\n",
    "        if agent_id:\n",
    "            filtered_logs = [log for log in filtered_logs if log['agent_id'] == agent_id]\n",
    "        if task_id:\n",
    "            filtered_logs = [log for log in filtered_logs if log['task_id'] == task_id]\n",
    "        return filtered_logs\n",
    "\n",
    "    def _load_deadlock_table(self) -> dict:\n",
    "        \"\"\"Loads the deadlock table from the JSON file.\"\"\"\n",
    "        try:\n",
    "            file_path = os.path.join(os.path.dirname(__file__), '..', 'data', 'deadlock_table.json')\n",
    "            with open(file_path, 'r') as f:\n",
    "                return json.load(f)\n",
    "        except FileNotFoundError:\n",
    "            print(\"Warning: deadlock_table.json not found. Using default deadlock handling.\")\n",
    "            return {\n",
    "                \"deadlock_scenarios\": {\n",
    "                    \"agent_blocked\": {\n",
    "                        \"action\": \"move_agent_back\",\n",
    "                        \"parameters\": {\"steps\": 1}\n",
    "                    }\n",
    "                },\n",
    "                \"default_resolution\": {\n",
    "                    \"action\": \"move_agent_back\",\n",
    "                    \"parameters\": {\"steps\": 1}\n",
    "                }\n",
    "            }\n",
    "\n",
    "    def _enqueue(self, agent: Agent, task: Task):\n",
    "        \"\"\"Helper method to enqueue tasks based on priority.\"\"\"\n",
    "        queue = self.priority_tasks if task.priority == 1 else self.tasks\n",
    "        queue.put({\n",
    "            'agent': agent,\n",
    "            'goal': task.goal_state,\n",
    "            'job': task.job\n",
    "        })\n",
    "\n",
    "    def order(self, agent: Agent, task: Task):\n",
    "        \"\"\"Orders a task for an agent by enqueuing it into the appropriate queue.\"\"\"\n",
    "        self._enqueue(agent, task)\n",
    "\n",
    "    def assign_task(self, agent: IAgent) -> None:\n",
    "        \"\"\"Assigns tasks from the priority queue first, then from the regular queue.\"\"\"\n",
    "        task_assigned = False\n",
    "\n",
    "        if not self.priority_tasks.empty():\n",
    "            task = self.priority_tasks.get()\n",
    "            agent.set_goal(task['goal'])\n",
    "            task_assigned = True\n",
    "            print(f\"Assigned high-priority Task {task['job']} to Agent {agent}.\")\n",
    "        \n",
    "        if not task_assigned and not self.tasks.empty():\n",
    "            task = self.tasks.get()\n",
    "            agent.set_goal(task['goal'])\n",
    "            print(f\"Assigned Task {task['job']} to Agent {agent}.\")\n",
    "\n",
    "    def detect_and_resolve_deadlock(self):\n",
    "        \"\"\"Detects deadlock and resolves it using the deadlock table.\"\"\"\n",
    "        blocked_agents = [agent for agent in self.agents if agent.state == \"blocked\"]\n",
    "\n",
    "        if len(blocked_agents) > 0:\n",
    "            # Identify deadlock scenario based on blocked agents\n",
    "            deadlock_type = self.identify_deadlock_type(blocked_agents)\n",
    "            scenario = self.deadlock_table[\"deadlock_scenarios\"].get(deadlock_type)\n",
    "            \n",
    "            if scenario:\n",
    "                print(f\"Deadlock detected: {scenario['description']}\")\n",
    "                print(f\"Resolution: {scenario['resolution']}\")\n",
    "                self.resolve_deadlock(deadlock_type, blocked_agents, scenario)\n",
    "            else:\n",
    "                # Use default resolution if scenario not found\n",
    "                default = self.deadlock_table[\"default_resolution\"]\n",
    "                print(f\"Deadlock detected. Using default resolution: {default['action']}\")\n",
    "                self.resolve_deadlock(deadlock_type, blocked_agents, default)\n",
    "\n",
    "    def identify_deadlock_type(self, blocked_agents: List[Agent]) -> str:\n",
    "        \"\"\"Identifies the type of deadlock based on the blocked agents' situation.\"\"\"\n",
    "        if len(blocked_agents) == 1:\n",
    "            return \"agent_blocked\"\n",
    "        elif len(blocked_agents) > 1:\n",
    "            return \"agents_blocked\"\n",
    "        else:\n",
    "            return \"path_blocked\"\n",
    "\n",
    "    def resolve_deadlock(self, deadlock_type: str, blocked_agents: List[Agent], scenario: dict):\n",
    "        \"\"\"Resolves the deadlock based on the deadlock type and blocked agents.\"\"\"\n",
    "        action = scenario[\"action\"]\n",
    "        params = scenario.get(\"parameters\", {})\n",
    "\n",
    "        if action == \"move_agent_back\":\n",
    "            self.move_agent_back(blocked_agents, params)\n",
    "        elif action == \"switch_agent_positions\":\n",
    "            self.switch_agent_positions(blocked_agents, params)\n",
    "        elif action == \"recalculate_path\":\n",
    "            self.recalculate_path(blocked_agents, params)\n",
    "        elif action == \"break_circular_wait\":\n",
    "            self.break_circular_wait(blocked_agents, params)\n",
    "        elif action == \"release_resources\":\n",
    "            self.release_resources(blocked_agents, params)\n",
    "\n",
    "    def move_agent_back(self, agents: List[Agent], params: dict):\n",
    "        \"\"\"Moves a blocked agent back along its path history.\"\"\"\n",
    "        agent = agents[0]\n",
    "        steps = params.get(\"steps\", 1)\n",
    "        \n",
    "        # Try to backtrack the specified number of steps\n",
    "        success = agent.backtrack(steps)\n",
    "        if not success:\n",
    "            print(f\"Warning: Could not backtrack {steps} steps for {agent}. Not enough path history.\")\n",
    "            # If we can't backtrack, try to move back one step at a time\n",
    "            for _ in range(steps):\n",
    "                if not agent.backtrack(1):\n",
    "                    break\n",
    "\n",
    "    def switch_agent_positions(self, agents: List[Agent], params: dict):\n",
    "        \"\"\"Switches positions between two blocked agents.\"\"\"\n",
    "        max_agents = params.get(\"max_agents\", 2)\n",
    "        if len(agents) > max_agents:\n",
    "            agents = agents[:max_agents]\n",
    "            \n",
    "        agent1, agent2 = agents\n",
    "        # Store current positions\n",
    "        pos1 = agent1.node\n",
    "        pos2 = agent2.node\n",
    "        \n",
    "        # Move agents to each other's positions\n",
    "        agent1.move(pos2)\n",
    "        agent2.move(pos1)\n",
    "        \n",
    "        print(f\"Switched positions between {agent1} and {agent2}.\")\n",
    "\n",
    "    def recalculate_path(self, agents: List[Agent], params: dict):\n",
    "        \"\"\"Recalculates the path for blocked agents.\"\"\"\n",
    "        algorithm = params.get(\"algorithm\", \"A*\")\n",
    "        max_attempts = params.get(\"max_attempts\", 3)\n",
    "        print(f\"Recalculating path for {agents} using {algorithm} (max attempts: {max_attempts})\")\n",
    "\n",
    "    def break_circular_wait(self, agents: List[Agent], params: dict):\n",
    "        \"\"\"Breaks circular wait by moving the lowest weight agent back.\"\"\"\n",
    "        priority = params.get(\"priority\", \"lowest_weight\")\n",
    "        if priority == \"lowest_weight\":\n",
    "            agent = min(agents, key=lambda a: a.weight)\n",
    "            self.move_agent_back([agent], {\"steps\": 1})\n",
    "            print(f\"Broke circular wait by moving lowest weight agent: {agent}\")\n",
    "\n",
    "    def release_resources(self, agents: List[Agent], params: dict):\n",
    "        \"\"\"Releases and reacquires resources for deadlocked agents.\"\"\"\n",
    "        timeout = params.get(\"timeout\", 5)\n",
    "        retry_interval = params.get(\"retry_interval\", 1)\n",
    "        print(f\"Releasing resources for {agents} (timeout: {timeout}s, retry interval: {retry_interval}s)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37cc1c0",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6d34a2",
   "metadata": {},
   "source": [
    "# Item Insertion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7267bf24",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e24e6dc",
   "metadata": {},
   "source": [
    "## Simmulated Annealing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1283eb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "class Candidate:\n",
    "    \"\"\"Represents a candidate solution with its state, cost, and efficiency metrics\"\"\"\n",
    "    def __init__(self, state, value, efficiency):\n",
    "        self.state = state\n",
    "        self.value = value\n",
    "        self.efficiency = efficiency\n",
    "\n",
    "class Problem:\n",
    "    \"\"\"Defines the warehouse optimization problem with all constraints\"\"\"\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "        self.items = []\n",
    "        self.box_sizes = {\n",
    "            'L': {'width': 180, 'bins': 3},\n",
    "            'M': {'width': 120, 'bins': 2},\n",
    "            'S': {'width': 60, 'bins': 1}\n",
    "        }\n",
    "        self.load_items()\n",
    "        \n",
    "        # Warehouse configuration\n",
    "        self.num_racks = 36\n",
    "        self.freezer_racks = {1, 2, 3, 4, 5, 6}\n",
    "        self.normal_racks = set(range(7, 37))\n",
    "        self.shelf_levels = 3\n",
    "        self.bins_per_shelf = 5\n",
    "        self.bin_size = 60\n",
    "        self.shelf_length = self.bins_per_shelf * self.bin_size\n",
    "        \n",
    "        self.weight_limits = {1: 400, 2: 250, 3: 150}\n",
    "        self.category_conflicts = {\n",
    "            'food': ['chemicals'],\n",
    "            'beverages': ['chemicals'],\n",
    "            'chemicals': ['food', 'beverages'],\n",
    "            'frozen': [],\n",
    "            'household goods': []\n",
    "        }\n",
    "\n",
    "    def load_items(self):\n",
    "        with open(self.filename, mode='r') as file:\n",
    "            reader = csv.DictReader(file)\n",
    "            for row in reader:\n",
    "                size = row['item_size'][0].upper()\n",
    "                if size not in self.box_sizes:\n",
    "                    raise ValueError(f\"Invalid item size '{row['item_size']}'\")\n",
    "                \n",
    "                self.items.append({\n",
    "                    'id': int(row['item_id']),\n",
    "                    'name': row['item_name'],\n",
    "                    'size': size,\n",
    "                    'category': row['category'].lower(),\n",
    "                    'weight': float(row['weight']),\n",
    "                    'frequency': float(row['frequency']),\n",
    "                    'is_frozen': row['category'].lower() == 'frozen'\n",
    "                })\n",
    "\n",
    "    def get_bin_requirements(self, size):\n",
    "        \"\"\"\n",
    "        Get bin requirements for an item size\n",
    "        \n",
    "        Args:\n",
    "            size: Item size ('L', 'M', or 'S')\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (bins_needed, possible_starting_positions)\n",
    "        \"\"\"\n",
    "        bins = self.box_sizes[size]['bins']\n",
    "        possible_starts = list(range(1, self.bins_per_shelf - bins + 2))\n",
    "        return bins, possible_starts\n",
    "\n",
    "    def generate_initial_state(self):\n",
    "        \"\"\"Generate initial random state respecting all constraints\"\"\"\n",
    "        state = {}\n",
    "        shelf_usage = defaultdict(set)  # {(rack, shelf): set of occupied bins}\n",
    "        \n",
    "        for item in self.items:\n",
    "            placed = False\n",
    "            attempts = 0\n",
    "            bins_needed, possible_starts = self.get_bin_requirements(item['size'])\n",
    "            \n",
    "            while not placed and attempts < 100:\n",
    "                # Choose appropriate racks\n",
    "                valid_racks = self.freezer_racks if item['is_frozen'] else self.normal_racks\n",
    "                rack = random.choice(list(valid_racks))\n",
    "                shelf = random.randint(1, self.shelf_levels)\n",
    "                \n",
    "                # Find available consecutive bins\n",
    "                available_starts = [\n",
    "                    s for s in possible_starts\n",
    "                    if all(b not in shelf_usage[(rack, shelf)] \n",
    "                      for b in range(s, s + bins_needed))\n",
    "                ]\n",
    "                \n",
    "                if available_starts:\n",
    "                    start = random.choice(available_starts)\n",
    "                    positions = list(range(start, start + bins_needed))\n",
    "                    \n",
    "                    # Place the item\n",
    "                    state[item['id']] = (rack, shelf, positions)\n",
    "                    for pos in positions:\n",
    "                        shelf_usage[(rack, shelf)].add(pos)\n",
    "                    placed = True\n",
    "                else:\n",
    "                    attempts += 1\n",
    "            \n",
    "            if not placed:\n",
    "                # Fallback placement (may violate constraints)\n",
    "                valid_racks = self.freezer_racks if item['is_frozen'] else self.normal_racks\n",
    "                rack = random.choice(list(valid_racks))\n",
    "                shelf = random.randint(1, self.shelf_levels)\n",
    "                start = random.randint(1, self.bins_per_shelf - bins_needed + 1)\n",
    "                positions = list(range(start, start + bins_needed))\n",
    "                state[item['id']] = (rack, shelf, positions)\n",
    "        \n",
    "        return state\n",
    "\n",
    "    def calculate_efficiency(self, state):\n",
    "        \"\"\"\n",
    "        Calculate shelf efficiency metrics\n",
    "        \n",
    "        Args:\n",
    "            state: Current solution state\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (perfect_shelves, good_shelves, poor_shelves, utilization)\n",
    "        \"\"\"\n",
    "        shelf_stats = defaultdict(lambda: {'used_bins': set(), 'weight': 0, 'categories': set()})\n",
    "        \n",
    "        # Track shelf usage\n",
    "        for item_id, (rack, shelf, positions) in state.items():\n",
    "            item = next(i for i in self.items if i['id'] == item_id)\n",
    "            shelf_stats[(rack, shelf)]['used_bins'].update(positions)\n",
    "            shelf_stats[(rack, shelf)]['weight'] += item['weight']\n",
    "            shelf_stats[(rack, shelf)]['categories'].add(item['category'])\n",
    "        \n",
    "        perfect = good = poor = 0\n",
    "        total_used = 0\n",
    "        \n",
    "        # Classify each shelf\n",
    "        for (rack, shelf), stats in shelf_stats.items():\n",
    "            used_width = len(stats['used_bins']) * self.bin_size\n",
    "            remaining = self.shelf_length - used_width\n",
    "            \n",
    "            if remaining == 0:\n",
    "                perfect += 1\n",
    "            elif remaining <= self.bin_size:  # Can fit at least one S\n",
    "                good += 1\n",
    "            elif remaining >= (self.shelf_length / 2):  # More than half empty\n",
    "                poor += 1\n",
    "            \n",
    "            total_used += used_width\n",
    "        \n",
    "        # Calculate overall utilization\n",
    "        total_space = self.num_racks * self.shelf_levels * self.shelf_length\n",
    "        utilization = total_used / total_space\n",
    "        \n",
    "        return (perfect, good, poor, utilization)\n",
    "\n",
    "    def evaluate(self, state):\n",
    "        \"\"\"\n",
    "        Evaluate the cost of a solution state\n",
    "        \n",
    "        Args:\n",
    "            state: Solution state to evaluate\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (total_cost, efficiency_metrics)\n",
    "        \"\"\"\n",
    "        cost = 0\n",
    "        shelf_stats = defaultdict(lambda: {'used_bins': set(), 'weight': 0, 'categories': set(), 'items': []})\n",
    "        \n",
    "        # Check hard constraints\n",
    "        for item_id, (rack, shelf, positions) in state.items():\n",
    "            item = next(i for i in self.items if i['id'] == item_id)\n",
    "            shelf_key = (rack, shelf)\n",
    "            stats = shelf_stats[shelf_key]\n",
    "            \n",
    "            # Track shelf usage\n",
    "            stats['used_bins'].update(positions)\n",
    "            stats['weight'] += item['weight']\n",
    "            stats['categories'].add(item['category'])\n",
    "            stats['items'].append(item)\n",
    "            \n",
    "            # Frozen items must be in freezer racks\n",
    "            if item['is_frozen'] and rack not in self.freezer_racks:\n",
    "                cost += 10000\n",
    "                \n",
    "            # Check weight limits\n",
    "            if stats['weight'] > self.weight_limits[shelf]:\n",
    "                cost += 1000\n",
    "                \n",
    "            # Check category conflicts\n",
    "            for other in stats['items']:\n",
    "                if other['category'] in self.category_conflicts[item['category']]:\n",
    "                    cost += 1000\n",
    "        \n",
    "        # Calculate soft costs\n",
    "        for item_id, (rack, shelf, positions) in state.items():\n",
    "            item = next(i for i in self.items if i['id'] == item_id)\n",
    "            cost += item['frequency'] * shelf  # Accessibility cost\n",
    "            cost += item['weight'] * shelf     # Weight distribution cost\n",
    "        \n",
    "        # Add efficiency metrics\n",
    "        perfect, good, poor, utilization = self.calculate_efficiency(state)\n",
    "        cost -= perfect * 50  # Reward perfect shelves\n",
    "        cost += poor * 100    # Penalize poor shelves\n",
    "        if utilization < 0.85:\n",
    "            cost += 1000 * (0.85 - utilization)  # Utilization penalty\n",
    "            \n",
    "        return cost, (perfect, good, poor, utilization)\n",
    "\n",
    "    def generate_neighbor(self, current_state):\n",
    "        \"\"\"Generate a valid neighboring state by moving one item\"\"\"\n",
    "        new_state = current_state.copy()\n",
    "        item_id = random.choice(list(new_state.keys()))\n",
    "        item = next(i for i in self.items if i['id'] == item_id)\n",
    "        \n",
    "        # Try up to 20 random moves\n",
    "        for _ in range(20):\n",
    "            # Choose appropriate racks\n",
    "            valid_racks = self.freezer_racks if item['is_frozen'] else self.normal_racks\n",
    "            rack = random.choice(list(valid_racks))\n",
    "            shelf = random.randint(1, self.shelf_levels)\n",
    "            \n",
    "            bins_needed, possible_starts = self.get_bin_requirements(item['size'])\n",
    "            \n",
    "            # Get current shelf usage\n",
    "            used_bins = set()\n",
    "            for other_id, (r, s, positions) in new_state.items():\n",
    "                if r == rack and s == shelf:\n",
    "                    used_bins.update(positions)\n",
    "            \n",
    "            # Find available consecutive bins\n",
    "            available_starts = [\n",
    "                s for s in possible_starts\n",
    "                if all(b not in used_bins for b in range(s, s + bins_needed))\n",
    "            ]\n",
    "            \n",
    "            if available_starts:\n",
    "                start = random.choice(available_starts)\n",
    "                positions = list(range(start, start + bins_needed))\n",
    "                new_state[item_id] = (rack, shelf, positions)\n",
    "                return new_state\n",
    "        \n",
    "        return current_state  # Return original if no valid move found\n",
    "\n",
    "\n",
    "def simulated_annealing(problem, initial_temp, cooling_rate, iterations):\n",
    "    \"\"\"\n",
    "    Perform simulated annealing optimization\n",
    "    \n",
    "    Args:\n",
    "        problem: Problem instance\n",
    "        initial_temp: Starting temperature\n",
    "        cooling_rate: Temperature reduction factor\n",
    "        iterations: Maximum iterations\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (best_state, best_cost, best_eff, cost_history, perfect_history, util_history, movement_log)\n",
    "    \"\"\"\n",
    "    current_state = problem.generate_initial_state()\n",
    "    current_cost, current_eff = problem.evaluate(current_state)\n",
    "    best_state = current_state.copy()\n",
    "    best_cost = current_cost\n",
    "    best_eff = current_eff\n",
    "    \n",
    "    # Progress tracking\n",
    "    cost_history = [current_cost]\n",
    "    perfect_history = [current_eff[0]]\n",
    "    util_history = [current_eff[3]]\n",
    "    movement_log = []\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        temp = initial_temp * (cooling_rate ** i)\n",
    "        if temp < 1e-6:\n",
    "            break\n",
    "            \n",
    "        neighbor = problem.generate_neighbor(current_state)\n",
    "        neighbor_cost, neighbor_eff = problem.evaluate(neighbor)\n",
    "        \n",
    "        # Acceptance probability\n",
    "        if neighbor_cost < current_cost or random.random() < math.exp((current_cost - neighbor_cost)/temp):\n",
    "            # Log changes\n",
    "            changed_items = [\n",
    "                item_id for item_id in current_state\n",
    "                if current_state[item_id] != neighbor.get(item_id, None)\n",
    "            ]\n",
    "            \n",
    "            for item_id in changed_items:\n",
    "                item = next(i for i in problem.items if i['id'] == item_id)\n",
    "                old_pos = current_state[item_id]\n",
    "                new_pos = neighbor[item_id]\n",
    "                reason = determine_move_reason(problem, item, old_pos, new_pos, neighbor_cost - current_cost)\n",
    "                movement_log.append(create_movement_record(item, old_pos, new_pos, reason, neighbor_cost - current_cost, i))\n",
    "            \n",
    "            current_state = neighbor\n",
    "            current_cost = neighbor_cost\n",
    "            current_eff = neighbor_eff\n",
    "            \n",
    "            if neighbor_cost < best_cost:\n",
    "                best_state = neighbor\n",
    "                best_cost = neighbor_cost\n",
    "                best_eff = neighbor_eff\n",
    "        \n",
    "        # Record progress\n",
    "        cost_history.append(current_cost)\n",
    "        perfect_history.append(current_eff[0])\n",
    "        util_history.append(current_eff[3])\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(f\"Iter {i}: Cost={current_cost}, Perfect={current_eff[0]}, Util={current_eff[3]:.1%}\")\n",
    "    \n",
    "    # Add initial to final movement records\n",
    "    initial_state = problem.generate_initial_state()\n",
    "    for item in problem.items:\n",
    "        item_id = item['id']\n",
    "        initial_pos = initial_state[item_id]\n",
    "        final_pos = best_state.get(item_id, None)\n",
    "        \n",
    "        if final_pos and initial_pos != final_pos:\n",
    "            reason = \"Initial optimization\"\n",
    "            cost_impact = best_cost - cost_history[0]\n",
    "            movement_log.append(create_movement_record(item, initial_pos, final_pos, reason, cost_impact, \"Initial\"))\n",
    "    \n",
    "    return best_state, best_cost, best_eff, cost_history, perfect_history, util_history, movement_log\n",
    "\n",
    "\n",
    "def create_movement_record(item, old_pos, new_pos, reason, cost_impact, iteration):\n",
    "    \"\"\"\n",
    "    Create a standardized movement record dictionary\n",
    "    \n",
    "    Args:\n",
    "        item: Item being moved\n",
    "        old_pos: Original position (rack, shelf, positions)\n",
    "        new_pos: New position (rack, shelf, positions)\n",
    "        reason: Reason for move\n",
    "        cost_impact: Cost change from this move\n",
    "        iteration: Iteration number\n",
    "        \n",
    "    Returns:\n",
    "        dict: Movement record\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'item_id': item['id'],\n",
    "        'item_name': item['name'],\n",
    "        'category': item['category'],\n",
    "        'size': item['size'],\n",
    "        'old_rack': old_pos[0],\n",
    "        'old_shelf': old_pos[1],\n",
    "        'old_positions': format_positions(old_pos[2]),\n",
    "        'new_rack': new_pos[0],\n",
    "        'new_shelf': new_pos[1],\n",
    "        'new_positions': format_positions(new_pos[2]),\n",
    "        'reason': reason,\n",
    "        'cost_impact': cost_impact,\n",
    "        'iteration': iteration\n",
    "    }\n",
    "\n",
    "\n",
    "def format_positions(positions):\n",
    "    \"\"\"\n",
    "    Format position list as human-readable string\n",
    "    \n",
    "    Args:\n",
    "        positions: List of bin positions\n",
    "        \n",
    "    Returns:\n",
    "        str: Formatted position string (e.g., \"2-4\" for [2,3,4])\n",
    "    \"\"\"\n",
    "    if len(positions) == 1:\n",
    "        return str(positions[0])\n",
    "    return f\"{positions[0]}-{positions[-1]}\"\n",
    "\n",
    "\n",
    "def determine_move_reason(problem, item, old_pos, new_pos, cost_change):\n",
    "    \"\"\"\n",
    "    Determine the reason for an item movement\n",
    "    \n",
    "    Args:\n",
    "        problem: Problem instance\n",
    "        item: Item being moved\n",
    "        old_pos: Original position\n",
    "        new_pos: New position\n",
    "        cost_change: Cost impact of move\n",
    "        \n",
    "    Returns:\n",
    "        str: Reason description\n",
    "    \"\"\"\n",
    "    # Frozen items\n",
    "    if item['is_frozen'] and new_pos[0] in problem.freezer_racks and old_pos[0] not in problem.freezer_racks:\n",
    "        return \"Moved to freezer rack\"\n",
    "    \n",
    "    # Category conflicts\n",
    "    # ... [category conflict checking logic] ...\n",
    "    \n",
    "    # Weight distribution\n",
    "    if new_pos[1] < old_pos[1]:  # Moved to lower shelf\n",
    "        return \"Better weight distribution\"\n",
    "    \n",
    "    # Space utilization\n",
    "    old_gaps = calculate_gaps(old_pos[2], problem.bins_per_shelf)\n",
    "    new_gaps = calculate_gaps(new_pos[2], problem.bins_per_shelf)\n",
    "    if min(new_gaps) > min(old_gaps):\n",
    "        return \"Improved space utilization\"\n",
    "    \n",
    "    return \"General optimization\" if cost_change < 0 else \"Exploratory move\"\n",
    "\n",
    "\n",
    "def calculate_gaps(positions, total_bins):\n",
    "    \"\"\"\n",
    "    Calculate gaps between occupied bins\n",
    "    \n",
    "    Args:\n",
    "        positions: List of occupied bin positions\n",
    "        total_bins: Total bins per shelf\n",
    "        \n",
    "    Returns:\n",
    "        list: Sizes of gaps between occupied bins\n",
    "    \"\"\"\n",
    "    occupied = set(positions)\n",
    "    gaps = []\n",
    "    current_gap = 0\n",
    "    \n",
    "    for bin in range(1, total_bins + 1):\n",
    "        if bin in occupied:\n",
    "            if current_gap > 0:\n",
    "                gaps.append(current_gap)\n",
    "            current_gap = 0\n",
    "        else:\n",
    "            current_gap += 1\n",
    "    \n",
    "    if current_gap > 0:\n",
    "        gaps.append(current_gap)\n",
    "    \n",
    "    return gaps if gaps else [0]\n",
    "\n",
    "\n",
    "\n",
    "def generate_movement_report(initial_state, best_state, problem, filename='item_movements.csv'):\n",
    "    \"\"\"Generate CSV with exact format requested\"\"\"\n",
    "    with open(filename, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow([\n",
    "            'item_id', 'name', 'category', 'size',\n",
    "            'initial_position', 'new_position'\n",
    "        ])\n",
    "        \n",
    "        for item in problem.items:\n",
    "            item_id = item['id']\n",
    "            old_pos = initial_state.get(item_id, (None, None, []))\n",
    "            new_pos = best_state.get(item_id, (None, None, []))\n",
    "            \n",
    "            if old_pos[0] and new_pos[0]:  # Only include properly placed items\n",
    "                writer.writerow([\n",
    "                    item_id,\n",
    "                    item['name'],\n",
    "                    item['category'],\n",
    "                    item['size'],\n",
    "                    f\"({old_pos[0]},{old_pos[1]},{format_positions(old_pos[2])})\",\n",
    "                    f\"({new_pos[0]},{new_pos[1]},{format_positions(new_pos[2])})\"\n",
    "                ])\n",
    "\n",
    "def generate_heatmaps(initial_state, best_state, problem):\n",
    "    \"\"\"Generate before/after heatmaps\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
    "    \n",
    "    # Prepare data\n",
    "    def prepare_heatmap_data(state):\n",
    "        heatmap = np.zeros((problem.shelf_levels, problem.num_racks))\n",
    "        for (rack, shelf, _) in state.values():\n",
    "            heatmap[shelf-1][rack-1] += 1\n",
    "        return heatmap\n",
    "    \n",
    "    # Initial state heatmap\n",
    "    im1 = ax1.imshow(prepare_heatmap_data(initial_state), cmap='YlOrRd')\n",
    "    ax1.set_title('Initial Item Distribution')\n",
    "    ax1.set_xlabel('Rack Number')\n",
    "    ax1.set_ylabel('Shelf Level')\n",
    "    fig.colorbar(im1, ax=ax1)\n",
    "    \n",
    "    # Optimized state heatmap\n",
    "    im2 = ax2.imshow(prepare_heatmap_data(best_state), cmap='YlOrRd')\n",
    "    ax2.set_title('Optimized Item Distribution')\n",
    "    ax2.set_xlabel('Rack Number')\n",
    "    ax2.set_ylabel('Shelf Level')\n",
    "    fig.colorbar(im2, ax=ax2)\n",
    "    \n",
    "    plt.savefig('placement_heatmaps.png')\n",
    "\n",
    "def format_positioSns(positions):\n",
    "    \"\"\"Improved bin formatting\"\"\"\n",
    "    if not positions:\n",
    "        return \"\"\n",
    "    if len(positions) == 1:\n",
    "        return str(positions[0])\n",
    "    return f\"{positions[0]}-{positions[-1]}\"\n",
    "def generate_visualization(cost_history, perfect_history, util_history):\n",
    "    \"\"\"\n",
    "    Generate optimization progress plots\n",
    "    \n",
    "    Args:\n",
    "        cost_history: List of cost values over iterations\n",
    "        perfect_history: List of perfect shelf counts\n",
    "        util_history: List of utilization percentages\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(cost_history)\n",
    "    plt.title('Cost Reduction Over Time')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Total Cost')\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(perfect_history)\n",
    "    plt.title('Perfect Shelves Over Time')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Count')\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(util_history)\n",
    "    plt.title('Space Utilization Over Time')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Utilization %')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('optimization_progress.png')\n",
    "\n",
    "\n",
    "def generate_text_report(problem, best_state, best_cost, best_eff):\n",
    "    \"\"\"\n",
    "    Generate detailed text report of final solution\n",
    "    \n",
    "    Args:\n",
    "        problem: Problem instance\n",
    "        best_state: Optimal solution state\n",
    "        best_cost: Solution cost\n",
    "        best_eff: Efficiency metrics\n",
    "    \"\"\"\n",
    "    shelf_details = defaultdict(list)\n",
    "    for item_id, (rack, shelf, positions) in best_state.items():\n",
    "        item = next(i for i in problem.items if i['id'] == item_id)\n",
    "        shelf_details[(rack, shelf)].append((item, positions))\n",
    "    \n",
    "    report = [\n",
    "        \"=\"*80,\n",
    "        \"WAREHOUSE OPTIMIZATION REPORT\",\n",
    "        \"=\"*80,\n",
    "        f\"\\nFinal Statistics:\",\n",
    "        f\"- Total Cost: {best_cost}\",\n",
    "        f\"- Perfect Shelves: {best_eff[0]} (fully packed)\",\n",
    "        f\"- Good Shelves: {best_eff[1]} (<60cm unused)\",\n",
    "        f\"- Poor Shelves: {best_eff[2]} (>150cm unused)\",\n",
    "        f\"- Space Utilization: {best_eff[3]:.1%}\",\n",
    "        \"\\n\" + \"=\"*80,\n",
    "        \"SHELF DETAILS (POORLY UTILIZED SHELVES):\",\n",
    "        \"=\"*80\n",
    "    ]\n",
    "    \n",
    "    # Show worst shelves\n",
    "    poor_shelves = sorted(\n",
    "        [(k, v) for k, v in shelf_details.items()],\n",
    "        key=lambda x: problem.shelf_length - sum(problem.box_sizes[i['size']]['width'] for i, _ in x[1]),\n",
    "        reverse=True\n",
    "    )[:10]  # Top 10 worst\n",
    "    \n",
    "    for (rack, shelf), items in poor_shelves:\n",
    "        used = sum(problem.box_sizes[i['size']]['width'] for i, _ in items)\n",
    "        report.append(\n",
    "            f\"\\nRack {rack} Shelf {shelf} (Used: {used}cm/{problem.shelf_length}cm):\"\n",
    "        )\n",
    "        for item, positions in items:\n",
    "            report.append(\n",
    "                f\"  - ID {item['id']}: {item['name']} ({item['size']}, \"\n",
    "                f\"{item['weight']}kg, {item['category']}) \"\n",
    "                f\"in positions {format_positions(positions)}\"\n",
    "            )\n",
    "    \n",
    "    with open('optimization_report.txt', 'w') as f:\n",
    "        f.write(\"\\n\".join(report))\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Initialize problem\n",
    "        problem = Problem('items.csv')\n",
    "        \n",
    "        # Get initial state before optimization\n",
    "        initial_state = problem.generate_initial_state()\n",
    "        \n",
    "        # Run optimization\n",
    "        print(\"Starting optimization...\")\n",
    "        results = simulated_annealing(\n",
    "            problem,\n",
    "            initial_temp=1000,\n",
    "            cooling_rate=0.995,\n",
    "            iterations=5000\n",
    "        )\n",
    "        best_state, best_cost, best_eff, *_ = results\n",
    "        \n",
    "        # Generate outputs\n",
    "        generate_movement_report(initial_state, best_state, problem)\n",
    "        generate_heatmaps(initial_state, best_state, problem)\n",
    "        generate_visualization(*results[3:6])  # Existing progress plots\n",
    "        generate_text_report(problem, best_state, best_cost, best_eff)\n",
    "        \n",
    "        print(\"\\nOptimization complete!\")\n",
    "        print(f\"- Final cost: {best_cost}\")\n",
    "        print(f\"- Space utilization: {best_eff[3]:.1%}\")\n",
    "        print(\"- CSV output: item_movements.csv\")\n",
    "        print(\"- Heatmaps: placement_heatmaps.png\")\n",
    "        print(\"- Progress plots: optimization_progress.png\")\n",
    "        print(\"- Report: optimization_report.txt\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42acadc6",
   "metadata": {},
   "source": [
    "# Path Finding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd2023e",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a04b904",
   "metadata": {},
   "source": [
    "## Greedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae9a512",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import heapq\n",
    "import math\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- File Paths ---\n",
    "BASE_DIR = os.path.dirname(os.path.abspath(__file__))\n",
    "MAP_FILE_PATH = os.path.join(BASE_DIR, \"..\", \"data\", \"map.json\")\n",
    "LOOKUP_TABLE_PATH = os.path.join(BASE_DIR, \"..\", \"data\", \"lookup_table.json\")\n",
    "\n",
    "# --- Helper Functions ---\n",
    "def load_json_file(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            return json.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading JSON from {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_node_coordinates(node_id, graph_nodes):\n",
    "    node = graph_nodes.get(node_id)\n",
    "    return (node['x'], node['y']) if node else (None, None)\n",
    "\n",
    "def heuristic_manhattan(n1, n2, nodes):\n",
    "    x1, y1 = get_node_coordinates(n1, nodes)\n",
    "    x2, y2 = get_node_coordinates(n2, nodes)\n",
    "    return abs(x1 - x2) + abs(y1 - y2) if None not in (x1, y1, x2, y2) else float('inf')\n",
    "\n",
    "def get_goal_node_from_lookup(item_id, table):\n",
    "    return table.get(item_id, {}).get(\"goal_node\")\n",
    "\n",
    "def reconstruct_path(came_from, current):\n",
    "    path = [current]\n",
    "    while current in came_from and came_from[current]:\n",
    "        current = came_from[current]\n",
    "        path.append(current)\n",
    "    return path[::-1]\n",
    "\n",
    "def greedy_search(start, goal, nodes, heuristic):\n",
    "    open_set = []\n",
    "    heapq.heappush(open_set, (heuristic(start, goal, nodes), start))\n",
    "    came_from = {start: None}\n",
    "    explored = set()\n",
    "\n",
    "    while open_set:\n",
    "        _, current = heapq.heappop(open_set)\n",
    "        if current in explored:\n",
    "            continue\n",
    "        explored.add(current)\n",
    "        if current == goal:\n",
    "            return reconstruct_path(came_from, current), explored\n",
    "\n",
    "        for neighbor in nodes[current].get(\"neighbours\", []):\n",
    "            if neighbor not in explored and not nodes[neighbor].get(\"locked\", False):\n",
    "                came_from[neighbor] = current\n",
    "                heapq.heappush(open_set, (heuristic(neighbor, goal, nodes), neighbor))\n",
    "\n",
    "    return None, explored\n",
    "\n",
    "def plot_statistics(path_ids, explored, warehouse_nodes, item_id):\n",
    "    heuristics = [\n",
    "        heuristic_manhattan(n, path_ids[-1], warehouse_nodes)\n",
    "        for n in path_ids[:-1]\n",
    "    ]\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(10, 6))\n",
    "    fig.suptitle(f\"Greedy Search Haul Statistics for {item_id}\")\n",
    "\n",
    "    axs[0].bar([\"Path Length\", \"Explored Nodes\"], [len(path_ids), len(explored)], color=[\"blue\", \"orange\"])\n",
    "    axs[0].set_ylabel(\"Count\")\n",
    "    axs[0].set_title(\"Path and Explored Nodes\")\n",
    "\n",
    "    axs[1].plot(range(1, len(heuristics) + 1), heuristics, marker='o', color=\"green\")\n",
    "    axs[1].set_xlabel(\"Step in Path\")\n",
    "    axs[1].set_ylabel(\"Heuristic to Goal\")\n",
    "    axs[1].set_title(\"Heuristic Values Along Path\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# --- Main ---\n",
    "def main():\n",
    "    warehouse_map = load_json_file(MAP_FILE_PATH)\n",
    "    lookup_table = load_json_file(LOOKUP_TABLE_PATH)\n",
    "    if not warehouse_map or not lookup_table:\n",
    "        print(\"Map or lookup table could not be loaded.\")\n",
    "        return\n",
    "\n",
    "    nodes = warehouse_map[\"nodes\"]\n",
    "    agent_start_node = \"N2-4\"  # Start node for the agent, can be modified if needed\n",
    "\n",
    "    # Iterate over all items in the lookup table\n",
    "    for item_id, item_data in lookup_table.items():\n",
    "        goal_node = get_goal_node_from_lookup(item_id, lookup_table)\n",
    "\n",
    "        if not goal_node or goal_node not in nodes:\n",
    "            print(f\"Invalid goal node for item {item_id}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Searching from {agent_start_node} to {goal_node} for item {item_id}\")\n",
    "        path, explored = greedy_search(agent_start_node, goal_node, nodes, heuristic_manhattan)\n",
    "\n",
    "        if path:\n",
    "            print(f\"Path found for {item_id}: {' -> '.join(path)}\")\n",
    "            plot_statistics(path, explored, nodes, item_id)\n",
    "        else:\n",
    "            print(f\"No path found for {item_id}.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cbe5b9",
   "metadata": {},
   "source": [
    "## A*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07992545",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from core.node import Node\n",
    "from math import inf\n",
    "from data.load_nodes_from_json import load_nodes_from_json \n",
    "\n",
    "def a_star_algorithm(start: Node, goal: Node) -> Optional[List[Node]]:\n",
    "    \"\"\"Wrapper function for the A* search algorithm.\n",
    "    \n",
    "    Args:\n",
    "        start: The starting node\n",
    "        goal: The goal node\n",
    "        \n",
    "    Returns:\n",
    "        Optional[List[Node]]: The path from start to goal if one exists, None otherwise\n",
    "    \"\"\"\n",
    "    search = AStarSearch(start, goal)\n",
    "    return search.search()\n",
    "\n",
    "class AStarSearch:\n",
    "    def __init__(self, start: Node, goal: Node):\n",
    "        self.start = start\n",
    "        self.goal = goal\n",
    "        self.open_list = []\n",
    "        self.closed_list = []\n",
    "        self.came_from = {}\n",
    "        self.g_scores = {start: float(0)}  # Store g-scores separately\n",
    "        self.f_scores = {start: self._heuristic(start)}  # Store f-scores separately\n",
    "\n",
    "    def search(self) -> Optional[List[Node]]:\n",
    "        \"\"\" Perform the A* search algorithm. \"\"\"\n",
    "        self.open_list.append(self.start)\n",
    "        while self.open_list:\n",
    "            current_node = self._get_lowest_f_score_node()\n",
    "            if current_node == self.goal:\n",
    "                return self._reconstruct_path(current_node)\n",
    "\n",
    "            self.open_list.remove(current_node)\n",
    "            self.closed_list.append(current_node)\n",
    "\n",
    "            for neighbor, cost in current_node.neighbours.items():\n",
    "                if neighbor in self.closed_list:\n",
    "                    continue\n",
    "                tentative_g_score = self.g_scores[current_node] + cost\n",
    "                if neighbor not in self.open_list:\n",
    "                    self.open_list.append(neighbor)\n",
    "                elif tentative_g_score >= self.g_scores.get(neighbor, inf):\n",
    "                    continue\n",
    "\n",
    "                self.came_from[neighbor] = current_node\n",
    "                self.g_scores[neighbor] = tentative_g_score\n",
    "                self.f_scores[neighbor] = tentative_g_score + self._heuristic(neighbor)\n",
    "\n",
    "        return None  # No path found\n",
    "\n",
    "    def _get_lowest_f_score_node(self) -> Node:\n",
    "        \"\"\" Get the node with the lowest f-score (g + h). \"\"\"\n",
    "        return min(self.open_list, key=lambda node: self.f_scores.get(node, inf))\n",
    "\n",
    "    def _reconstruct_path(self, current_node: Node) -> List[Node]:\n",
    "        \"\"\" Reconstruct the path from start to goal. \"\"\"\n",
    "        path = [current_node]\n",
    "        while current_node in self.came_from:\n",
    "            current_node = self.came_from[current_node]\n",
    "            path.append(current_node)\n",
    "        return path[::-1]  # Reverse to get the path from start to goal\n",
    "\n",
    "    def _heuristic(self, node: Node) -> float:\n",
    "        \"\"\" Calculate the heuristic value for a node. \"\"\"\n",
    "        return self.get_distance(node, self.goal)\n",
    "\n",
    "    def get_distance(self, n1: Node, n2: Node) -> float:\n",
    "        \"\"\" Calculate the Euclidean distance between two nodes. \"\"\"\n",
    "        return ((n1.x - n2.x) ** 2 + (n1.y - n2.y) ** 2) ** 0.5\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Load nodes from JSON file\n",
    "    nodes = load_nodes_from_json(\"backend/data/facts.json\",\"Euclidean\")\n",
    "    \n",
    "    # Define start and goal nodes (example)\n",
    "    start_node = nodes[\"N3-1\"]\n",
    "    goal_node = nodes[\"N3-24\"]\n",
    "    \n",
    "    # Run A* algorithm\n",
    "    path = a_star_algorithm(start_node, goal_node)\n",
    "    \n",
    "    if path:\n",
    "        print(\"Path found:\", [str(node) for node in path])\n",
    "    else:\n",
    "        print(\"No path found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e15b1d",
   "metadata": {},
   "source": [
    "# Layout Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a63211",
   "metadata": {},
   "source": [
    "## Genetic Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc11a187",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import copy\n",
    "import math\n",
    "\n",
    "# --- DUMMY DATA AND HELPERS (Assume these are well-defined for your actual data) ---\n",
    "DUMMY_ITEM_DB = {\n",
    "    'itemA': {'weight': 15, 'category': 'food', 'slots': 1}, 'itemB': {'weight': 25, 'category': 'food', 'slots': 2},\n",
    "    'itemC': {'weight': 5, 'category': 'beverages', 'slots': 1}, 'itemD': {'weight': 40, 'category': 'household goods', 'slots': 3},\n",
    "    'itemE': {'weight': 50, 'category': 'household goods', 'slots': 2}, 'itemF': {'weight': 2, 'category': 'chemicals', 'slots': 1},\n",
    "    'itemG': {'weight': 8, 'category': 'food', 'slots': 1}, 'itemH': {'weight': 12, 'category': 'beverages', 'slots': 2},\n",
    "    'itemI': {'weight': 30, 'category': 'household goods', 'slots': 1}, 'itemJ': {'weight': 60, 'category': 'household goods', 'slots': 3},\n",
    "    'itemK_frozen': {'weight': 10, 'category': 'frozen', 'slots': 1}, 'itemL_frozen': {'weight': 18, 'category': 'frozen', 'slots': 2},\n",
    "    'itemM_frozen_sml': {'weight': 5, 'category': 'frozen', 'slots': 1}, 'itemN_food_sml': {'weight': 7, 'category': 'food', 'slots': 1},\n",
    "}\n",
    "MAX_SLOTS_PER_SHELF = 5\n",
    "HEAVY_ITEM_THRESHOLD = 20\n",
    "\n",
    "def get_item_details(item_id):\n",
    "    return DUMMY_ITEM_DB.get(item_id, {'weight': 0, 'category': 'unknown', 'slots': 1})\n",
    "\n",
    "COMPATIBILITY_MATRIX = {\n",
    "    'food': {'food': True, 'beverages': True, 'household goods': True, 'chemicals': False, 'frozen': False},\n",
    "    'beverages': {'food': True, 'beverages': True, 'household goods': True, 'chemicals': False, 'frozen': False},\n",
    "    'household goods': {'food': True, 'beverages': True, 'household goods': True, 'chemicals': False, 'frozen': False},\n",
    "    'chemicals': {'food': False, 'beverages': False, 'household goods': False, 'chemicals': True, 'frozen': False},\n",
    "    'frozen': {'food': False, 'beverages': False, 'household goods': False, 'chemicals': False, 'frozen': True},\n",
    "}\n",
    "\n",
    "def is_compatible_on_shelf(shelf_items_categories, new_item_category, is_rack_frozen):\n",
    "    if is_rack_frozen and new_item_category != 'frozen':\n",
    "        return False # Non-frozen item cannot go into a frozen rack's shelf\n",
    "    if not is_rack_frozen and new_item_category == 'frozen':\n",
    "        return False # Frozen item cannot go into a non-frozen rack's shelf\n",
    "\n",
    "    for existing_category in shelf_items_categories:\n",
    "        if new_item_category == 'frozen' and existing_category != 'frozen': return False\n",
    "        if existing_category == 'frozen' and new_item_category != 'frozen': return False\n",
    "        if not COMPATIBILITY_MATRIX.get(existing_category, {}).get(new_item_category, False):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def get_shelf_categories(shelf_items):\n",
    "    return [get_item_details(item_id)['category'] for item_id in shelf_items]\n",
    "\n",
    "# --- RACK DATA (Placeholder - you'll get this from your Warehouse object) ---\n",
    "# Assume each rack object/dict has an 'id' and 'is_frozen' attribute\n",
    "# and a 'layout' attribute: [[L1_items], [L2_items], [L3_items]]\n",
    "DUMMY_RACKS_DATA = {\n",
    "    'R01': {'id': 'R01', 'is_frozen': False, 'layout': [['itemA', 'itemC'], ['itemD'], ['itemF', 'itemN_food_sml']]},\n",
    "    'R02': {'id': 'R02', 'is_frozen': False, 'layout': [['itemJ'], [], ['itemB', 'itemG']]},\n",
    "    'R03': {'id': 'R03', 'is_frozen': False, 'layout': [[], ['itemE', 'itemH'], []]},\n",
    "    'R04': {'id': 'R04', 'is_frozen': True, 'layout': [['itemK_frozen'], ['itemL_frozen'], []]},\n",
    "    'R05': {'id': 'R05', 'is_frozen': True, 'layout': [['itemM_frozen_sml'],[],[]]}\n",
    "}\n",
    "# --- Genetic Algorithm Class (Revised for Pool of Racks) ---\n",
    "\n",
    "class GeneticAlgorithmPoolOptimizer:\n",
    "    def __init__(self, initial_rack_pool_layouts, is_optimizing_frozen_racks,\n",
    "                 generations=50, population_size=30, tournament_size=3,\n",
    "                 crossover_rate=0.8, mutation_rate=0.1, elite_size=2):\n",
    "        \"\"\"\n",
    "        Initializes GA for a pool of racks (either all frozen or all non-frozen).\n",
    "        Args:\n",
    "            initial_rack_pool_layouts (list): List of rack layouts.\n",
    "                Each element is {'id': str, 'is_frozen': bool, 'layout': [[L1], [L2], [L3]]}.\n",
    "            is_optimizing_frozen_racks (bool): True if this GA instance is for frozen racks.\n",
    "        \"\"\"\n",
    "        if not initial_rack_pool_layouts:\n",
    "            raise ValueError(\"Initial rack pool cannot be empty.\")\n",
    "\n",
    "        self.is_optimizing_frozen_racks = is_optimizing_frozen_racks\n",
    "        self.num_racks_in_pool = len(initial_rack_pool_layouts)\n",
    "\n",
    "        # Population: list of individuals. Each individual is a list of rack data dicts.\n",
    "        self.population = []\n",
    "        for _ in range(population_size):\n",
    "            # Create a deep copy of the initial pool for each individual in the population\n",
    "            individual = copy.deepcopy(initial_rack_pool_layouts)\n",
    "            self.population.append(individual)\n",
    "\n",
    "        # Introduce initial variations (more advanced mutation might be needed for diversity)\n",
    "        # For simplicity, we'll rely on the main mutation operator during evolution.\n",
    "        # Or, apply a light initial shuffle/mutation to each individual if desired.\n",
    "\n",
    "        self.generations = generations\n",
    "        self.population_size = population_size\n",
    "        self.tournament_size = tournament_size\n",
    "        self.crossover_rate = crossover_rate\n",
    "        self.mutation_rate = mutation_rate # Chance for an individual (pool state) to be mutated\n",
    "        self.rack_mutation_rate = 0.2 # Chance for a rack within an individual to be part of mutation\n",
    "        self.shelf_mutation_rate = 0.1 # Chance for a shelf to be chosen for item move/swap\n",
    "        self.elite_size = elite_size\n",
    "        self.fitness_cache = {}\n",
    "\n",
    "        # Fitness weights (these might need different tuning for frozen vs non-frozen)\n",
    "        self.w_util = 0.40\n",
    "        self.w_purity = 0.15\n",
    "        self.w_weight = 0.20\n",
    "        self.w_compat = 0.20 # Compatibility is handled more by rack type now\n",
    "        self.w_empty = 0.05\n",
    "\n",
    "    def _get_shelf_slots_used(self, shelf_items):\n",
    "        return sum(get_item_details(item_id)['slots'] for item_id in shelf_items)\n",
    "\n",
    "    def _validate_and_repair_shelf(self, shelf_items, is_rack_frozen):\n",
    "        validated_items = []\n",
    "        slots_used = 0\n",
    "        for item_id in shelf_items:\n",
    "            item_detail = get_item_details(item_id)\n",
    "            # Basic check: frozen items only in frozen racks, non-frozen only in non-frozen\n",
    "            if is_rack_frozen and item_detail['category'] != 'frozen':\n",
    "                continue # Skip non-frozen item for a frozen rack's shelf\n",
    "            if not is_rack_frozen and item_detail['category'] == 'frozen':\n",
    "                continue # Skip frozen item for a non-frozen rack's shelf\n",
    "\n",
    "            if slots_used + item_detail['slots'] <= MAX_SLOTS_PER_SHELF:\n",
    "                current_shelf_categories = get_shelf_categories(validated_items)\n",
    "                if is_compatible_on_shelf(current_shelf_categories, item_detail['category'], is_rack_frozen):\n",
    "                    validated_items.append(item_id)\n",
    "                    slots_used += item_detail['slots']\n",
    "        return validated_items\n",
    "\n",
    "    def _validate_and_repair_rack_layout(self, rack_data): # rack_data is {'id':.., 'is_frozen':.., 'layout':..}\n",
    "        is_frozen = rack_data['is_frozen']\n",
    "        for i in range(len(rack_data['layout'])):\n",
    "            rack_data['layout'][i] = self._validate_and_repair_shelf(rack_data['layout'][i], is_frozen)\n",
    "        return rack_data\n",
    "\n",
    "    def _calculate_fitness_for_single_rack(self, rack_data): # rack_data is {'id':.., 'is_frozen':.., 'layout':..}\n",
    "        rack_layout = rack_data['layout']\n",
    "        is_rack_frozen = rack_data['is_frozen']\n",
    "\n",
    "        total_utilization = 0; total_purity = 0; weight_penalty = 0\n",
    "        compatibility_penalty_rack = 0; empty_shelf_penalty = 0\n",
    "        num_shelves = 3\n",
    "\n",
    "        for level_idx, shelf_items in enumerate(rack_layout):\n",
    "            slots_used = self._get_shelf_slots_used(shelf_items)\n",
    "            shelf_utilization = slots_used / MAX_SLOTS_PER_SHELF if MAX_SLOTS_PER_SHELF > 0 else 0\n",
    "            total_utilization += shelf_utilization\n",
    "\n",
    "            shelf_item_details = [get_item_details(item_id) for item_id in shelf_items]\n",
    "            categories_on_shelf = set(details['category'] for details in shelf_item_details)\n",
    "\n",
    "            for details in shelf_item_details:\n",
    "                if is_rack_frozen and details['category'] != 'frozen':\n",
    "                    compatibility_penalty_rack += 50 # Severe penalty for non-frozen in frozen rack\n",
    "                if not is_rack_frozen and details['category'] == 'frozen':\n",
    "                    compatibility_penalty_rack += 50 # Severe penalty for frozen in non-frozen rack\n",
    "                if level_idx > 0 and details['weight'] > HEAVY_ITEM_THRESHOLD:\n",
    "                    weight_penalty += details['weight'] * level_idx * 0.01 # Scaled penalty\n",
    "\n",
    "            if categories_on_shelf:\n",
    "                total_purity += 1.0 / len(categories_on_shelf)\n",
    "                # Check within-shelf compatibility (already partially handled by validate_and_repair)\n",
    "                current_shelf_cats = list(categories_on_shelf)\n",
    "                for i in range(len(current_shelf_cats)):\n",
    "                    for j in range(i + 1, len(current_shelf_cats)):\n",
    "                        if not is_compatible_on_shelf([current_shelf_cats[i]], current_shelf_cats[j], is_rack_frozen):\n",
    "                             compatibility_penalty_rack += 2 # Smaller penalty, as validate should catch most\n",
    "            else:\n",
    "                total_purity += 1.0 # Max purity for empty shelf\n",
    "\n",
    "            is_empty = not shelf_items\n",
    "            if level_idx > 0 and is_empty and level_idx -1 >=0 and \\\n",
    "               self._get_shelf_slots_used(rack_layout[level_idx-1]) < MAX_SLOTS_PER_SHELF * 0.5:\n",
    "                empty_shelf_penalty += 0.5\n",
    "            elif level_idx == 0 and is_empty and any(len(s) > 0 for s in rack_layout[1:]):\n",
    "                 empty_shelf_penalty += 1\n",
    "\n",
    "        avg_utilization = total_utilization / num_shelves if num_shelves > 0 else 0\n",
    "        avg_purity = total_purity / num_shelves if num_shelves > 0 else 0\n",
    "\n",
    "        fitness = (self.w_util * avg_utilization) + (self.w_purity * avg_purity) - \\\n",
    "                  (self.w_weight * weight_penalty) - (self.w_compat * compatibility_penalty_rack) - \\\n",
    "                  (self.w_empty * empty_shelf_penalty)\n",
    "        return max(0, fitness)\n",
    "\n",
    "\n",
    "    def _calculate_overall_fitness(self, individual_pool_state): # individual_pool_state is a list of rack_data dicts\n",
    "        # For caching, convert the whole state to a hashable form\n",
    "        # Sorting by rack ID ensures consistent hashing for the same overall state\n",
    "        sorted_racks_for_hash = sorted(individual_pool_state, key=lambda r: r['id'])\n",
    "        individual_tuple = tuple(\n",
    "            (rack['id'], tuple(tuple(sorted(shelf)) for shelf in rack['layout']))\n",
    "            for rack in sorted_racks_for_hash\n",
    "        )\n",
    "\n",
    "        if individual_tuple in self.fitness_cache:\n",
    "            return self.fitness_cache[individual_tuple]\n",
    "\n",
    "        total_fitness_sum = 0\n",
    "        for rack_data in individual_pool_state:\n",
    "            total_fitness_sum += self._calculate_fitness_for_single_rack(rack_data)\n",
    "        \n",
    "        avg_fitness = total_fitness_sum / self.num_racks_in_pool if self.num_racks_in_pool > 0 else 0\n",
    "        self.fitness_cache[individual_tuple] = avg_fitness\n",
    "        return avg_fitness\n",
    "\n",
    "    def _tournament_selection(self):\n",
    "        # ... (similar to before, but operates on self.population of individuals (pools))\n",
    "        # Ensure it calls self._calculate_overall_fitness\n",
    "        if not self.population: raise ValueError(\"Population empty.\")\n",
    "        tournament_candidates_indices = random.sample(range(len(self.population)), self.tournament_size)\n",
    "        tournament_candidates = [self.population[i] for i in tournament_candidates_indices]\n",
    "        \n",
    "        best_in_tournament = max(tournament_candidates, key=self._calculate_overall_fitness)\n",
    "        return best_in_tournament\n",
    "\n",
    "\n",
    "    def _crossover(self, parent1_pool_state, parent2_pool_state):\n",
    "        # parentX_pool_state is a list of rack_data dicts\n",
    "        child1_pool_state = copy.deepcopy(parent1_pool_state)\n",
    "        child2_pool_state = copy.deepcopy(parent2_pool_state)\n",
    "\n",
    "        if random.random() < self.crossover_rate:\n",
    "            # Iterate through corresponding racks in the two parent pools\n",
    "            # Assumes parent1 and parent2 have racks in the same order (e.g., sorted by ID initially)\n",
    "            # Or, better, ensure racks are identifiable (e.g., by ID) and map them.\n",
    "            # For simplicity now, assume same order based on initial pool.\n",
    "            for rack_idx in range(self.num_racks_in_pool):\n",
    "                # For each shelf level\n",
    "                for level in range(3): # L1, L2, L3\n",
    "                    if random.random() < 0.3: # Chance to swap this specific shelf level between these two racks\n",
    "                        # Ensure rack_idx is valid for both children\n",
    "                        if rack_idx < len(child1_pool_state) and rack_idx < len(child2_pool_state):\n",
    "                            # Swap the shelf contents for this level\n",
    "                            shelf1_content = child1_pool_state[rack_idx]['layout'][level]\n",
    "                            shelf2_content = child2_pool_state[rack_idx]['layout'][level]\n",
    "                            child1_pool_state[rack_idx]['layout'][level] = shelf2_content\n",
    "                            child2_pool_state[rack_idx]['layout'][level] = shelf1_content\n",
    "            \n",
    "            # Validate all racks in the new children pools\n",
    "            for i in range(self.num_racks_in_pool):\n",
    "                if i < len(child1_pool_state): child1_pool_state[i] = self._validate_and_repair_rack_layout(child1_pool_state[i])\n",
    "                if i < len(child2_pool_state): child2_pool_state[i] = self._validate_and_repair_rack_layout(child2_pool_state[i])\n",
    "        \n",
    "        return child1_pool_state, child2_pool_state\n",
    "\n",
    "    def _mutate(self, individual_pool_state):\n",
    "        mutated_pool = copy.deepcopy(individual_pool_state)\n",
    "        if random.random() > self.mutation_rate: # Chance to mutate this entire pool state\n",
    "            return mutated_pool # No mutation for this individual\n",
    "\n",
    "        # Attempt to swap items between shelves of two different racks in the pool\n",
    "        if self.num_racks_in_pool < 2: # Need at least two racks to swap between\n",
    "            return mutated_pool\n",
    "\n",
    "        # Select two different racks from the pool for potential item swap\n",
    "        rack_idx1, rack_idx2 = random.sample(range(self.num_racks_in_pool), 2)\n",
    "        \n",
    "        rack1_data = mutated_pool[rack_idx1]\n",
    "        rack2_data = mutated_pool[rack_idx2]\n",
    "\n",
    "        # Ensure racks are of the same type (both frozen or both non-frozen) for swapping\n",
    "        if rack1_data['is_frozen'] != rack2_data['is_frozen']:\n",
    "            return mutated_pool # Cannot swap between frozen and non-frozen racks directly here\n",
    "\n",
    "        # Try a few times to find a valid swap\n",
    "        for _attempt in range(5): # Max 5 attempts for a valid swap\n",
    "            # Select a random shelf from each rack\n",
    "            shelf_level1 = random.randrange(3)\n",
    "            shelf_level2 = random.randrange(3) # Can be same or different level\n",
    "\n",
    "            shelf1_items = rack1_data['layout'][shelf_level1]\n",
    "            shelf2_items = rack2_data['layout'][shelf_level2]\n",
    "\n",
    "            if not shelf1_items or not shelf2_items: continue # Need items on both shelves\n",
    "\n",
    "            # Select a random item from each shelf\n",
    "            item1_idx = random.randrange(len(shelf1_items))\n",
    "            item2_idx = random.randrange(len(shelf2_items))\n",
    "            item1_id = shelf1_items[item1_idx]\n",
    "            item2_id = shelf2_items[item2_idx]\n",
    "\n",
    "            item1_details = get_item_details(item1_id)\n",
    "            item2_details = get_item_details(item2_id)\n",
    "\n",
    "            # Constraint 1: Items must have the same slot size\n",
    "            if item1_details['slots'] != item2_details['slots']:\n",
    "                continue\n",
    "\n",
    "            # Temporarily perform the swap to check validity\n",
    "            original_shelf1_item = shelf1_items.pop(item1_idx)\n",
    "            original_shelf2_item = shelf2_items.pop(item2_idx)\n",
    "\n",
    "            shelf1_items.insert(item1_idx, item2_id) # Item2 goes to shelf1\n",
    "            shelf2_items.insert(item2_idx, item1_id) # Item1 goes to shelf2\n",
    "\n",
    "            # Constraint 2 & 3 & 4: Validate both shelves after swap (compatibility, capacity, weight for L1)\n",
    "            # We simplify validation by just checking the modified shelves.\n",
    "            # A full re-validation might be safer but more costly.\n",
    "            \n",
    "            temp_shelf1_validated = self._validate_and_repair_shelf(list(shelf1_items), rack1_data['is_frozen'])\n",
    "            temp_shelf2_validated = self._validate_and_repair_shelf(list(shelf2_items), rack2_data['is_frozen'])\n",
    "\n",
    "            # Check if the swapped items are still present after validation (meaning swap was valid capacity-wise)\n",
    "            # and that the shelves are still compatible overall.\n",
    "            valid_swap = True\n",
    "            if item2_id not in temp_shelf1_validated or item1_id not in temp_shelf2_validated:\n",
    "                valid_swap = False\n",
    "            \n",
    "            # Check overall compatibility of the new shelves\n",
    "            if valid_swap:\n",
    "                shelf1_cats = get_shelf_categories(temp_shelf1_validated)\n",
    "                for cat_idx in range(len(shelf1_cats)): # Check internal compat\n",
    "                    if not is_compatible_on_shelf(shelf1_cats[:cat_idx], shelf1_cats[cat_idx], rack1_data['is_frozen']):\n",
    "                        valid_swap = False; break\n",
    "                if not valid_swap: continue\n",
    "\n",
    "                shelf2_cats = get_shelf_categories(temp_shelf2_validated)\n",
    "                for cat_idx in range(len(shelf2_cats)):\n",
    "                    if not is_compatible_on_shelf(shelf2_cats[:cat_idx], shelf2_cats[cat_idx], rack2_data['is_frozen']):\n",
    "                        valid_swap = False; break\n",
    "                if not valid_swap: continue\n",
    "\n",
    "\n",
    "            # Weight constraint (simplified for this mutation):\n",
    "            # if shelf_level1 > 0 and item2_details['weight'] > HEAVY_ITEM_THRESHOLD: valid_swap = False\n",
    "            # if shelf_level2 > 0 and item1_details['weight'] > HEAVY_ITEM_THRESHOLD: valid_swap = False\n",
    "            # A more robust check would involve the items being replaced.\n",
    "            # For now, rely on the main fitness function to penalize bad weight distribution over time.\n",
    "\n",
    "            if valid_swap:\n",
    "                # print(f\"  MUTATION: Swapped {item1_id} (R{rack1_data['id']}-L{shelf_level1+1}) with {item2_id} (R{rack2_data['id']}-L{shelf_level2+1})\")\n",
    "                rack1_data['layout'][shelf_level1] = temp_shelf1_validated\n",
    "                rack2_data['layout'][shelf_level2] = temp_shelf2_validated\n",
    "                break # Successful swap, exit attempt loop\n",
    "            else:\n",
    "                # Revert swap\n",
    "                shelf1_items.pop(item1_idx)\n",
    "                shelf1_items.insert(item1_idx, original_shelf1_item)\n",
    "                shelf2_items.pop(item2_idx)\n",
    "                shelf2_items.insert(item2_idx, original_shelf2_item)\n",
    "        \n",
    "        # Validate all racks in the pool after potential mutations\n",
    "        for i in range(self.num_racks_in_pool):\n",
    "            mutated_pool[i] = self._validate_and_repair_rack_layout(mutated_pool[i])\n",
    "            \n",
    "        return mutated_pool\n",
    "\n",
    "    def run(self):\n",
    "        self.fitness_cache = {}\n",
    "        # Initialize best_solution_pool with a deepcopy of the first individual\n",
    "        best_solution_pool = copy.deepcopy(self.population[0])\n",
    "        best_overall_fitness = self._calculate_overall_fitness(best_solution_pool)\n",
    "        print(f\"Initial Avg Fitness for {'Frozen' if self.is_optimizing_frozen_racks else 'Non-Frozen'} Pool: {best_overall_fitness:.4f}\")\n",
    "\n",
    "        for generation in range(self.generations):\n",
    "            # Calculate fitness for all individuals in the population\n",
    "            pop_with_fitness = []\n",
    "            for individual_pool in self.population:\n",
    "                fitness = self._calculate_overall_fitness(individual_pool)\n",
    "                pop_with_fitness.append((fitness, individual_pool))\n",
    "            \n",
    "            pop_with_fitness.sort(key=lambda x: x[0], reverse=True)\n",
    "            self.population = [item[1] for item in pop_with_fitness] # Update population\n",
    "\n",
    "            current_gen_best_fitness = pop_with_fitness[0][0]\n",
    "            if current_gen_best_fitness > best_overall_fitness:\n",
    "                best_overall_fitness = current_gen_best_fitness\n",
    "                best_solution_pool = copy.deepcopy(pop_with_fitness[0][1])\n",
    "                print(f\"  Gen {generation}: New Best Avg Pool Fitness = {best_overall_fitness:.4f}\")\n",
    "            elif generation % 5 == 0:\n",
    "                 print(f\"  Gen {generation}: Current Avg Pool Fitness = {best_overall_fitness:.4f}\")\n",
    "\n",
    "            next_generation_population = []\n",
    "            if self.elite_size > 0:\n",
    "                next_generation_population.extend(self.population[:self.elite_size])\n",
    "\n",
    "            while len(next_generation_population) < self.population_size:\n",
    "                parent1 = self._tournament_selection()\n",
    "                parent2 = self._tournament_selection()\n",
    "                child1, child2 = self._crossover(parent1, parent2)\n",
    "                \n",
    "                next_generation_population.append(self._mutate(child1))\n",
    "                if len(next_generation_population) < self.population_size:\n",
    "                    next_generation_population.append(self._mutate(child2))\n",
    "            \n",
    "            self.population = next_generation_population[:self.population_size]\n",
    "            self.fitness_cache = {} # Clear cache for the next generation\n",
    "\n",
    "        print(f\"Finished GA for {'Frozen' if self.is_optimizing_frozen_racks else 'Non-Frozen'} Pool. Best Avg Fitness: {best_overall_fitness:.4f}\")\n",
    "        return best_solution_pool\n",
    "\n",
    "\n",
    "# --- Main Orchestration Logic ---\n",
    "def get_rack_data_from_warehouse(warehouse_object, rack_id):\n",
    "    # !! CRITICAL PLACEHOLDER !!\n",
    "    # Replace this with logic to fetch a specific rack's data (id, is_frozen, layout)\n",
    "    # from your actual 'warehouse_object'.\n",
    "    # The layout should be [[L1_items], [L2_items], [L3_items]]\n",
    "    rack_info = DUMMY_RACKS_DATA.get(rack_id)\n",
    "    if rack_info:\n",
    "        return copy.deepcopy(rack_info) # Return a copy to avoid modifying dummy data directly\n",
    "    raise ValueError(f\"Rack ID {rack_id} not found in dummy data.\")\n",
    "\n",
    "def get_all_rack_ids_from_warehouse(warehouse_object, frozen_only=None):\n",
    "    # !! CRITICAL PLACEHOLDER !!\n",
    "    # Replace this with logic to get all rack IDs from your 'warehouse_object'.\n",
    "    # If frozen_only is True, return only frozen rack IDs.\n",
    "    # If frozen_only is False, return only non-frozen rack IDs.\n",
    "    # If frozen_only is None, return all (not used in this version).\n",
    "    ids = []\n",
    "    for r_id, r_data in DUMMY_RACKS_DATA.items():\n",
    "        if frozen_only is True and r_data['is_frozen']:\n",
    "            ids.append(r_id)\n",
    "        elif frozen_only is False and not r_data['is_frozen']:\n",
    "            ids.append(r_id)\n",
    "    return ids\n",
    "\n",
    "def evaluate_overall_efficiency_for_pool(rack_pool_layouts):\n",
    "    if not rack_pool_layouts: return 0.0\n",
    "    total_slots_used_pool = 0\n",
    "    total_possible_slots_pool = 0\n",
    "    for rack_data in rack_pool_layouts:\n",
    "        rack_layout = rack_data['layout']\n",
    "        total_possible_slots_pool += MAX_SLOTS_PER_SHELF * 3\n",
    "        for shelf_items in rack_layout:\n",
    "            total_slots_used_pool += sum(get_item_details(item_id)['slots'] for item_id in shelf_items)\n",
    "    return total_slots_used_pool / total_possible_slots_pool if total_possible_slots_pool > 0 else 0.0\n",
    "\n",
    "\n",
    "def run_warehouse_reordering_ga(warehouse_object):\n",
    "    print(\"--- Starting Warehouse Reordering GA ---\")\n",
    "    all_optimized_racks = {}\n",
    "\n",
    "    # --- Parameters for GA (can be tuned) ---\n",
    "    ga_config = {\n",
    "        \"generations\": 50,       # Number of generations\n",
    "        \"population_size\": 20,   # Number of \"entire warehouse states\" in population\n",
    "        \"tournament_size\": 3,\n",
    "        \"crossover_rate\": 0.8,\n",
    "        \"mutation_rate\": 0.15,   # Increased mutation for more exploration\n",
    "        \"elite_size\": 2\n",
    "    }\n",
    "\n",
    "    # 1. Optimize Non-Frozen Racks\n",
    "    print(\"\\n--- Optimizing NON-FROZEN Rack Pool ---\")\n",
    "    non_frozen_rack_ids = get_all_rack_ids_from_warehouse(warehouse_object, frozen_only=False)\n",
    "    if non_frozen_rack_ids:\n",
    "        initial_non_frozen_pool = [get_rack_data_from_warehouse(warehouse_object, r_id) for r_id in non_frozen_rack_ids]\n",
    "        print(f\"Initial Non-Frozen Pool Efficiency: {evaluate_overall_efficiency_for_pool(initial_non_frozen_pool):.2%}\")\n",
    "\n",
    "        non_frozen_ga = GeneticAlgorithmPoolOptimizer(\n",
    "            initial_rack_pool_layouts=initial_non_frozen_pool,\n",
    "            is_optimizing_frozen_racks=False,\n",
    "            **ga_config\n",
    "        )\n",
    "        best_non_frozen_pool_state = non_frozen_ga.run()\n",
    "        for rack_data in best_non_frozen_pool_state:\n",
    "            all_optimized_racks[rack_data['id']] = rack_data\n",
    "        print(f\"Final Optimized Non-Frozen Pool Efficiency: {evaluate_overall_efficiency_for_pool(best_non_frozen_pool_state):.2%}\")\n",
    "    else:\n",
    "        print(\"No non-frozen racks to optimize.\")\n",
    "\n",
    "    # 2. Optimize Frozen Racks\n",
    "    print(\"\\n--- Optimizing FROZEN Rack Pool ---\")\n",
    "    frozen_rack_ids = get_all_rack_ids_from_warehouse(warehouse_object, frozen_only=True)\n",
    "    if frozen_rack_ids:\n",
    "        initial_frozen_pool = [get_rack_data_from_warehouse(warehouse_object, r_id) for r_id in frozen_rack_ids]\n",
    "        print(f\"Initial Frozen Pool Efficiency: {evaluate_overall_efficiency_for_pool(initial_frozen_pool):.2%}\")\n",
    "        \n",
    "        frozen_ga = GeneticAlgorithmPoolOptimizer(\n",
    "            initial_rack_pool_layouts=initial_frozen_pool,\n",
    "            is_optimizing_frozen_racks=True,\n",
    "            **ga_config # Can use different params for frozen if needed\n",
    "        )\n",
    "        best_frozen_pool_state = frozen_ga.run()\n",
    "        for rack_data in best_frozen_pool_state:\n",
    "            all_optimized_racks[rack_data['id']] = rack_data\n",
    "        print(f\"Final Optimized Frozen Pool Efficiency: {evaluate_overall_efficiency_for_pool(best_frozen_pool_state):.2%}\")\n",
    "    else:\n",
    "        print(\"No frozen racks to optimize.\")\n",
    "\n",
    "    print(\"\\n--- Warehouse Reordering Complete ---\")\n",
    "    return all_optimized_racks\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # This warehouse_object would be an instance of your actual Warehouse class\n",
    "    # For testing, we pass None and rely on placeholder functions using DUMMY_RACKS_DATA\n",
    "    dummy_warehouse_object = None \n",
    "    \n",
    "    optimized_warehouse_state = run_warehouse_reordering_ga(dummy_warehouse_object)\n",
    "\n",
    "    print(\"\\n\\n--- Final State of All Optimized Racks ---\")\n",
    "    if optimized_warehouse_state:\n",
    "        for rack_id, rack_data in optimized_warehouse_state.items():\n",
    "            is_frz = \"(Frozen)\" if rack_data['is_frozen'] else \"(Non-Frozen)\"\n",
    "            eff = evaluate_overall_efficiency_for_pool([rack_data]) # Efficiency for this single rack\n",
    "            print(f\"Rack ID: {rack_id} {is_frz}, Layout: {rack_data['layout']}, Efficiency: {eff:.2%}\")\n",
    "    else:\n",
    "        print(\"No optimization was performed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "warehouse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
